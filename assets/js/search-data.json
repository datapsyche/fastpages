{
  
    
        "post0": {
            "title": "My First Post in FastPages Blog",
            "content": "About . So I&#39;m just checking out the new fastpages blogging platform and this is my first post on this platform .",
            "url": "https://datapsyche.github.io/fastpages/jupyter/2020/04/10/jithin_test.html",
            "relUrl": "/jupyter/2020/04/10/jithin_test.html",
            "date": " • Apr 10, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://datapsyche.github.io/fastpages/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://datapsyche.github.io/fastpages/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Introduction to Eloquent Javascript",
            "content": "Eloquent Javascript . Chapter-1 . Javascript is built into every modern web browser and is available on almost every device. A sample program in javascript looks like. . let total = 0, count = 1; while (count &lt;= 10){ total + = count; count + = 1; } console.log(total); // -&gt; 55 . the same program can also be written as . console.log(sum(range(1,10))); // -&gt; 55 . Javascript was introduced in 1995, as a way to add programs to webpages in Netscape Navigator browser. Javascript is now mostly used in traditional websites to provide various forms of interactivity and cleverness. Javascript is nothing related to java and it was marketing decision to name it similar to highle popular java language. ECMA script standard maintains javascript standards. Javascript are not only used by web browsers but also by databases such as MongoDB and CouchDB use javascript as scripting and query language. .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2019/03/06/Javascript-Refresher.html",
            "relUrl": "/markdown/2019/03/06/Javascript-Refresher.html",
            "date": " • Mar 6, 2019"
        }
        
    
  
    
        ,"post4": {
            "title": "Data Mining Map by Saed Sayad",
            "content": "Data Mining Map by Saeed Sayad . Data Science can be broadly divided into two approaches explaining the past or predicting the future by means of data analysis. Data Science is a multi disciplinary field that combines statistics, machine learning, artificial intelligence and database technology. . . Business have accumulated data over the years and with the help of data science we are able extract valuable knowledge from this data. Lets understand how each field in above diagram contribute to Data Science. . Statistics is used in Data Science for collecting , classifying, summarising, organising, analysing and interpreting data. Artificial Intelligence contributes to Data Science by simulating intelligent behaviours from the underlying data. Machine Learning contributes to data science by coming up with algorithms that improve automatically through experience. Database Technology is necessary for collecting, storing and managing data so users can retrieve, add, update or remove data. . Now what do we do in Data Science ?? . In Laymans language we analyse data to explain the past or to predict the future. . Explaining the past . For explaining the past we need to do Data Exploration - It is all about describing the data by means of statistical and visualization technique. Data Exploration helps in order to bring important aspects of data into focus for further analysis. . Univariate Analysis - Exploring variables one by one . Variables can be of two types categorical or numerical. Each type of variable has is own recommended way for analysis or for graphical plotting. . Categorical Variables - A categorical or discrete variable has two or more categories (values). There are two types of categorical variables . Nominal Variable - No intrinsic ordering for its categories (eg - Gender) | Ordinal Variable - A clear ordering is there (eg - Temperature [low, medium, high] | . Frequency tables are the best way to analyse such variables . Pie Chart and Bar Chart are commonly used for visual analysis. . . | Numerical Variables - takes any value within a finite or infinite interval eg:- height, weight, temperature, blood glucose. There are two types of numerical variables, intervals and ratio. . Interval Variables - Values whose differences are interpret able. (temperature in centigrade). Data in Interval scale can be added or subtracted but cannot be meaningfully multiplied or divided. | Ratio Variable - Data in ratio variable has values with a true zero and can be added, subtracted ,multiplied or divided. (eg- weight) | . How do we analyse Numerical variables ? Below table describe the various methods to analyse Numerical variable . Statistics Visualization Equation Description . Count | Histogram | N | Number of observations | . Minimum | Box Plot | Min | smallest value among the observations | . Maximum | Box Plot | Max | largest value among the observations | . Mean | Box Plot | | Sum of values / count | . Median | Box Plot | | Middle value below and above lies equal number of values | . Mode | Histogram |   | Most frequent value in observation set | . Quantile | Box Plot | Q~k~ | Cut points that divides observations into multiple groups with equal number of values | . Range | Box plot | Max - Min | Difference between Maximum and minimum | . Variance | Histogram | | Measure of Data Dispersion | . Standard Deviation | Histogram | | Square root of Variance | . Coefficient Of Deviation | Histogram | | Measure of Data Dispersion divided by Mean | . Skewness | Histogram | | Measure of symmetry or asymmetry of data | . Kurtosis | Histogram |   | Measure of whether the data are peaked or flat relative to a normal distribution | . | . | Bivariate Analysis - Simultaneous analysis of 2 Variables. Explores the concept of relationship between 2 variables. There are 3 types of bivariate analysis . Numerical &amp; Numerical - Scatter Plot is a visual representation of two numerical variables, We can infer patterns from this. | Linear Correlation - quantifies the linear relationship between two numerical variables | . | Categorical &amp; Categorical - Stacked Column Chart - Compares the percentage each category from one variable contributes to a total across categories of second variable | Combination Charts - two or more different type of charts for each variable (bar chart and chart) to show how one variable is affecting other variable | Chi Square Test -Used to determine association between categorical variables, based on differences between expected frequencies (e) and observed frequency (n) in one or more categories in the frequency table. The test returns a probability for the computed chi square and degree of freedom, probability of 0 means complete dependency between categorical variable and probability of 1 means two categorical variables are completely independent | . | Numerical &amp; Categorical - Line Chart with error Bars -Error Bars show standard Error in that particular Category. | Combination Chart - either line or Bar chart ( line for numerical variable and bar for categorical) | Z test and T test - Assess averages of two groups are statistically different from each other If probability between Z is small the difference between two averages is more significant. We use T test when number of observation is less than 30 | Anova test Assess whether the averages of more than two groups are statistically different from each other, Analysis is appropriate for comparing the averages of a numerical variable for more than two categories of a categorical variable. | . | . | . Predicting the Future . For predicting the future we make use of models. Hence the name Predictive Modeling. Here we try to predict the outcome. if the outcome is Categorical we call it classification, if it is numerical we call it regression. Descriptive modelling or clustering is the assignment of observations into clusters. Association Rule can help us find interesting association among observations. . Classification Algorithms . Here output variable is categorical. Classification algorithms could be broadly divided into 4 main groups. . Frequency Table Based . Zero R method - simplest classification method exclusively relies on target and ignores all predictors. ZeroR classifier simply predicts the majority class. It has no predictability power however it is usefull for determining Baseline performance as a benchmark for other classification methods. . Construct a frequency table and select its most frequent value. . | One R method - simple yet accurate classifiaction algorithm that generates one rule for each predictor in the data and then selects the rule with smallest total error as its one rule. For each predictor, For each value of that predictor make a rule as follows: Count how often each value of target appears. Find the most frequent class Make the rule assign that class to this value of the predictor Calculate the total error of the rules of each predictor Choose the predictor with smallest total error . | Naive Bayes Method - Based on Naive Bayes Theorem with independence assumption between predictors. Naive Bayes model is easy to build, useful for large data set. Naive Bayes often useful and is widely used as it outperforms classification methods. P(c/x)=(P(x/c)∗P(c))/P(x)P(c/x) = (P(x/c)*P(c))/P(x)P(c/x)=(P(x/c)∗P(c))/P(x) P(c/x)P(c/x)P(c/x) - Posterior Probability . P(x/c)P(x/c)P(x/c) - Likelihood . P(c)P(c)P(c) - Class probability . P(x)P(x)P(x) - Predictor Prior Probability . P(c/X)=P(x 1 /C)∗P(x 2 /C)x....P(x n /C)∗P(C)P(c/X) = P(x~1~/C) * P(x~2~/C) x ....P(x~n~/C) * P(C)P(c/X)=P(x 1 /C)∗P(x 2 /C)x....P(x n /C)∗P(C) | . | .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2019/01/11/Machine-Learning-Refresher.html",
            "relUrl": "/markdown/2019/01/11/Machine-Learning-Refresher.html",
            "date": " • Jan 11, 2019"
        }
        
    
  
    
        ,"post5": {
            "title": "Word Embedding Literature Review",
            "content": "Word Embeddings - Literature Review . Word embeddings are representations of a document library capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words. | Vector representation of a particular word. | . How to create a word Embedding ? - Word2vec is the most popular technique to learn word embeddings, it is using shallow neural network. . Why do we need Word Embedding ? - In One hot encoding all the words are independent of each other. Word Embedding aims to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of data. The underlying principle is that a word is characterized by the company it keeps. . Paper Reading - Evaluation of sentence embedding in downstream and linguistic probing tasks. . by Christian S Perone, Roberto Silvera, Thomas Paula . Word Embedding ranges from Neural Probablistic Language Model, Word2vec, GloVe, and ELMO. Most of them rely on distributional linguistic hypothesis but differ on assumption of how meaning or context are modeled to produce the word embeddings. Word embeddings provide high quality representation for words but representing sentences, paragraphs is still an open research. . Most common approach is Bag of Words model. Here we create a Bag of words word vector using simple arithmetic mean of the embeddings for the words in a sentence along the words dimension. Though the approach seems trivial and limited lot of improvements have taken place in Bag of Words model by using weighted averages and modifying them using singular value decomposition (SVD) the method is called smooth inverse frequency. . word embedding based on Encoder / Decoder architectures - Skip Thought - a skip gram model from word2vec was abstracted to form sentence level encoder trained on self supervised fashion. .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2019/01/10/Word-Embeddings-Literature-Review.html",
            "relUrl": "/markdown/2019/01/10/Word-Embeddings-Literature-Review.html",
            "date": " • Jan 10, 2019"
        }
        
    
  
    
        ,"post6": {
            "title": "Introduction to Siamese Networks",
            "content": "Siamese Recurrent Architectures for Learning Sentence Similarity . Paper by Jonas Mueller &amp; Aditya Thyagarajan - http://www.mit.edu/~jonasm/info/MuellerThyagarajan_AAAI16.pdf . Introduction . Mikolov demonstrated the effectiveness of neural word representations for analogies and other NLP tasks (2013), ever since interest shifted towards extensions of these ideas beyond the individual word-level to larger bodies of text like sentences where a mapping is learned to represent each sentence as a fixed length vector (Kiros 2015 and Mikolov 2014). RNNs are naturally suited for variable length inputs like sentences, LSTM is the most preferred type of RNNs. RNN’s are Turing complete optimization of the weight matrices is difficult due to the backpropagated vanishing gradients hence LSTM was preferred. . Here we consider a supervised learning setting where each training example consists of a pair of sequences of fixed-size vectors along a single label y for the pair. sequences may be of different lengths. The task here can be considered as scoring similarity between sentences given example pairs whose semantic similarity labelled . . Related Work .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2019/01/10/Siamese-Recurrent-Architectures-for-Learning-Sentence-Similarity.html",
            "relUrl": "/markdown/2019/01/10/Siamese-Recurrent-Architectures-for-Learning-Sentence-Similarity.html",
            "date": " • Jan 10, 2019"
        }
        
    
  
    
        ,"post7": {
            "title": "Matching Resumes to Jobs via Deep Siamese Networks",
            "content": "Matching Resumes to Jobs via Deep Siamese Network . Introduction . Given a collection of semi structured job description J and some known matched and unmatched resume / job description pairs &lt;r,j&gt; the task is to retrieve matching job descriptions for any existing or new resume r. . | Traditional engines fail to understand the underlying semantic meanings of different resumes and have not kept pace with recent progress in machine learning and natural language processing (NLP) techniques. . | These solutions are generally driven by manually engineered features and set of rules with predefined weights to keywords which lean to an inefficient and ineffective search experience for job candidates and not generally scalable. . | Text based tasks rely heavily on representations that could be effectively learned. such representation must capture the underlying semantics among textual elements, where textual elements can be sequences, words or characters. . | State of the art models like Bag of words and TF-IDF are effective in many NLP tasks, in the context of understanding the underlying semantics they are inefficient due to their inherent term specificity. . | Models like Glove, Word2Vec are less effective at document level. . | Siamese Networks possess the capability of learning a similarity metric from the available training records. Here Siamese networks posses the capability of learning a similarity metric from the available training records. here CNN convolutional neural networks with a contrastive loss energy function joining the twin network at the top. The twin network share the weights with eachother . | . Proposed Approach . Consists of a pair of identical CNN that contains repeating convolution, Max pooling and leaky rectified linear unit layers with a fully connected layer at the top. | CNN is used because any part of text in resumes and job description can influence the semantics of the word. In order to effectively capture the CNN should see the entire input at once hence CNN is used, Use of CNN could be contrasted by use of LSTM networks. LSTM usually read from left to right hence Bidirectional LSTM are required. which is even more computationally intensive. hence CNN was considered. CNN grows a larger receptive field as we stack more and more layers. It gives a desired effect in a controllable fashion with a low computational cost. | CNN gives a non linear projection to the resumes and JD in semantic space. The semantic vectors yielded from CNN are connected to a layer measuring similarity between resume and JD. The contrastive loss function combines the measured distance and the label. The gradient of the loss function with respect to weights and biases shared by subnetworks are computed using back propagation. | Parameter sharing is the highlight of siamese networks. Training the network with a shared set of parameter not only reduce number of parameter but also represent consistency of the representation of JD and Resume in a semantic space. The shared parameters are learned with the aim to minimize / Maximize the distance between resumes and JD. Doc2Vec is used for document embedding of resume and jd. This vector representation is given as input to the network. | . Experiments . Baseline Method - 6 commonly used representations 1) Word n_grams 2) TF-IDF - Baseline methods to compare with due to their effectiveness in variety of NLP tasks 3) BOW : The word frequency from training text is selected and count of each word is used as features. 4) Bag of Means : The avearage word2vec embedding of the training data is used as a feature set. 5) Doc2Vec : An unsupervised algorithm that learns fixed-length feature representation from variable length pieces of text. 6) CNN . Cosine Similarity was the final step with all these baseline models in order to find the similarity of &lt;r,j&gt; pair. The Value of threshold for cosine similarity is determined by grid search on values. . Dataset and Experimental Setting - . Dataset consists of 1314 resumes and a set of 3809 JDs. hence generating a pair of 5,005,026 distinct &lt;r,j&gt; pair with label as 0 or 1. Annotated the corpus in semi supervised fashion. First few were manually annotated by interns. Each resume and JD was preprocessed by lower casing, stemming and special character removal. Performed training in batches of size 128 . length of semantic vector was 256. depth of CNN was 4, Kernel width of max pooling is 100 and convolution is 10 and learning rate was set to 0.01. Adam optimization is used to update parameters of the subnetworks. . Result and Analysis . Table shows the result of the various methods on task of matching resumes to jobs. Compare with 6 baseline methods. Performance of proposed siamese adaptation of CNN is significantly better than a all of the baseline models. . ​ .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2019/01/10/Matching-Resumes-to-Job-Via-Deep-Siamese-Networks.html",
            "relUrl": "/markdown/2019/01/10/Matching-Resumes-to-Job-Via-Deep-Siamese-Networks.html",
            "date": " • Jan 10, 2019"
        }
        
    
  
    
        ,"post8": {
            "title": "Learning Text Similarity with Siamese Recurrent Networks",
            "content": "Learning Text Similarity with Siamese Recurrent Networks . Authors - Paul Neculoiu, Maarten Versteegh and Mihai Rotaru. . Link to the Paper - http://www.aclweb.org/anthology/W16-16#page=162 . Abstract . Presents a deep architecture for learning similarity metric on variable length character sequences. | Model combines a stack of character-level bidirectional LSTM’s with a Siamese architecture. | Learns to project variable length strings into a fixed dimensional embedding space by using only information about similarity between pairs of strings. | Model could be applied to task of job title normalization based on a manually annotated taxonomy. model learns a representation that is selective to differences in the input reflect semantic differences (eg:- Java developer vs HR manager) but also invariant to non semantic string differences (eg- Java developer vs Java programmer) | . Introduction . Representation that express semantic similarity and dissimilarity between textual elements is important in NLP. Word similarity models (Mikolov 2013) is applied in diverse settings such as sentiment analysis and recommender system. | Semantic textual similarity is used in automatic summarization (Ponzanelli 2015), debate analysis (Boltuzic and Snajder 2015) and paraphrase detection (Socher 2011). | . | Measuring semantic similarity between texts is necessary for Information Extraction (IE). This process is also called Normalization ie. to put pieces of information in standard format. eg:- ‘12pm, noon, 12:00h’ all should map to same representation. Normalization is essential for retrieving actionable information from free unstructured text. | This paper presents a system for job title normalization. task here is to receive an input string and map it to one of a finite set of job codes which were predefined externally. It could be considered as a highly Multi-class classification problem, but here the focus is on learning representation of the strings such that synonymous job titles are close together. | . Related Work . Representation learning through neural network (Auto encoders, Hinton 2006) is invariant to differences in the input that do not matter for that task and selective to differences. | Siamese network (Bromley 1993) is an architecture for non linear metric learning with similarity information. The network naturally learns representations that reveals the invariance and selectivity through explicit information about similarity between pairs of object. Siamese network learns an invariant and selective representation directly through the use of similarity and dissimilarity information. | An Autoencoder learns invariance through added noise and dimensionality reduction in the bottleneck layer and selectivity through the condition that the input should be reproduced by the decoding part of the network. | Siamese architecture was originally applied to signature verification (Bromley 1993) and has been used in Vision application. Siamese convolutional networks are used for face verification (Chopra 2005) and dimensionality reduction on image features (Hadsell 2006). They have been also used for diverse tasks as unsupervised acoustic modelling (Synnaeve 2014), Learning food preference (Yang 2015), Scene detection (Baraldi, 2015). In NLP Siamese network with convolutional layers have been applied to matching sentences (Hu 2014) and for learning semantic entailment (Mueller 2016). | Job Title Normalization is framed as a classification task (Javed 2014) as it has large number of classes. Multi stage classifier have shown good results. But there are disadvantages to this approach Expense of data acquisition for training number of classes will exponentially increase the data requirement. | Once a classification error is identified, we need to retrain the entire classifier with new sample added to correct the class | Using traditional classifier do not allow for transfer learning. | . | Use of String similarity measure to classify input strings here the advantage is there is no need to train the system hence improvement can be made by adding job title strings to the data. | Modeling similarity directly based on pairs of inputs Siamese networks lend themselves well to the semantic invariance present in job title normalization. | . Siamese Recurrent Neural Network . Recurrent Neural Networks are neural networks adapted for sequence data. LSTM variant of RNN has particularly had success in tasks related to natural language processing like text classification and language translation. . | Bi directional RNN incorporate both future and past context by running the reverse f input through a separate RNN. The output of combined model at each time step is simply the concatenation of outputs from the forward and backward networks. | Siamese networks are dual branch networks with tied weights, they consist of the same network copied and merged with an energy function. The training set for Siamese network consists of triplets (x1,x2 and y) where x1 and x2 are character sequences and y indicates whether x1 and x2 are similar or dissimilar (0 or 1). The aim of training is to minimize the distance in an embedding space between similar pairs and maximize the distance between dissimilar pairs. | . Contrastive Loss Function . The Network contains 4 layers of Bidirectional LSTM nodes. the activations at each time step of the final BLSTM are averaged to produce a fixed dimensional output. This output is projected through a single densely connected feed forward layer. Energy of the model E is the cosine similarity between embeddings of x1 and x2. | The Network used has 4 BLSTM layers with 64 dimensional Hidden vectors h and memory c. there are connections at each time step between layers. Outputs of the last layer are averaged over time and this 128 dimensional vector is used as input to a dense feed forward layer. | The input strings are padded to produce a sequence of 100 characters with input string randomly placed in this sequence. The parameters of the model are optimized using Adam method and trained until convergence. Dropout technique (Srivastava 2014) on recurrent units and between layers (probability .4) is done to prevent overfitting. | . Experiment . Small dataset based on handmade taxonomy of job titles is used. After each experiment the dataset is augmented by adding new source of variance. | Baseline - ngram matcher (Daelemans 2004). given an input string, this matcher looks up closest neighbour from base taxonomy by maximizing a similarity scoring function. The matcher subsequently labels input string with neighbour’s group label. This similarity function has the properties that it is easy to compute and doesn’t require any learning and is particularly insensitive to appending extra words in the input string. | Here the test set consists of pairs of strings, the first of which is the input string and the second a target group label from the base taxonomy. The network model projects the input string into the embedding space and searched for its nearest neighbor under cosine distance from the base taxonomy. The test records a hit only if the neighbors group label matches the target. | . Data and Data Augmentation . Handmade Job Title taxonomy partition set of 19,927 job titles into 4,431 groups. Job Titles were manually and semi automatically collected from resumes and vacancy postings. Each was manually assigned a group such that job titles in a group are close together. . | The wide variety of different semantic relations between and within groups is considered as an asset to be exploited by the model. . | The groups are not equal in size largest group has 130 job titles and smallest group has just one. The long tail may affect the models ability to accurately learn to represent smallest group. . | 4 stage process starting from base taxonomy of job titles at each stage an augmentation of data which focuses on a particular property and a test that probes the model for behavior related to that property. each stage build on next stage hence previous augmentations are included. . | The dataset consists of pairs of strings sampled from the taxonomy in a 4:1 ratio of between class (negative pairs) to within-class (positive pairs) . Testing Criteria . | Typo and Spelling invariance - Slight differences in spelling from taxonomy should be intelligently picked. to induce this invariance we augment the base taxonomy by extending it with positive sample pairs consisting of job title strings and the same string but with 20% characters randomly substituted and 5% deleted. . | Synonyms - Model should be invariant to synonym substitution we augment the data set by substituting words in job titles by synonyms. first source is a manually constructed job title synonym set consisting of around 1100 job titles each with between 1 and 10 synonyms. Second source is by induction the complements of the matching strings from a synonym candidate. . | Extra Words - To be useful model should be invariant to the present of additional words. . | Feedback - Model should be corrigible. we should be able to append the model when it performs badly. . | . Result . Comparison was done with baseline n-gram system and proposed neural network models on the four tests. Both n-gram matching system and the proposed model have near complete invariance to the simple typos. . Discussions . A model architecture for learning text similarity based on Siamese recurrent neural networks is presented. This architecture learns a series of embedding spaces based on specific augmentation of the dataset used to train the model. The embedding spaces captured important invariances of the input, the model was invariant to spelling variations, synonym replacements and superfluous words. | The ability of the system to learn invariances are due the contrastive loss function combined with the stack of recurrent layers. Using separate loss functions for similar and dissimilar samples helps the model maintain selectivity while learning invariances over different sources of variability. | . Further Improvements . Incorporating convolutional layers in addition to the recurrent layers. | Investigating a triplet loss function instead of contrastive loss used in this study | Comparison to a stronger baseline would serve further development. | Job Title taxonomy used in the current study exhibits a hierarchical structure that is not fully exploited. further research could attempt to learn a single embedding which would preserve the separation between groups at different levels of hierarchy. | .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2019/01/10/Learning-Text-Similarity-with-Siamese-Networks.html",
            "relUrl": "/markdown/2019/01/10/Learning-Text-Similarity-with-Siamese-Networks.html",
            "date": " • Jan 10, 2019"
        }
        
    
  
    
        ,"post9": {
            "title": "Landing AI - AI transformation Playbook",
            "content": "Landing AI -AI transformation PlayBook - Quick Study . Recommendations are primarily meant for larger enterprises with a market cap from $500M to $500B. | First few AI projects needs to be successful rather than being most valuable. | AI solution can be build in 6-12 months when working with internal teams sharing the deep domain knowledge. Identifying technically feasible projects is a important along with having clearly defined and measurable objective to create business value. | Building an in house AI team should be considered as a long term project. AI team could sit under CTO, CIO or CDO. An Inhouse AI team would have roles like ML engineer, Data Engineer, Data Scientist and AI product Manager. | Providing Broad AI training - Flipped Classroom pedagogy is gaining traction especially in AI community. Employee training is now much more affordable and Learning and Development team could easily come up with study groups, MOOCs community to motivate employees to gain AI Knowledge. Executives and senior business leaders: ( ≥ 4 hours training) | Leaders of divisions carrying out AI projects: (≥12 hours training with willingness to upskill.) | AI engineer trainees: (≥100 hours training with continuous learning) | . | Data is key asset for AI system, Strategic Data Acquisition is required. Unified data warehouses comes valuable for an AI system. | AI communication strategy is very much necessary with Investors, Regulators(government), Customers and with Talent. Clear Internal AI communication strategy can help reduce the uncertainty revolving around AI strategy. | AI transformation program may take 2-3 years but in 6-12 months results would start to come in and in 2 years should be able to break even depending on the quality and impact of AI system which is introduced. | .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2019/01/10/Landing-AI-AI-Transformation-PlayBook.html",
            "relUrl": "/markdown/2019/01/10/Landing-AI-AI-Transformation-PlayBook.html",
            "date": " • Jan 10, 2019"
        }
        
    
  
    
        ,"post10": {
            "title": "Doc2Vec Summary",
            "content": "Distributed Representations of Sentences and Documents . Most algorithms typically require text input to be represented as a fixed-length vector. Bag of words / bag of n grams are the most common due to its simplicity, efficiency and often surprising accuracy. Bag of words has many disadvantages, Word order is gone and hence different sentences can have same representation. Bag of n grams considers word order in short context, as it has data sparsity and high dimensionality. . Paragraph vectors is an unsupervised framework that learns continuous distributed vector representations for pieces of texts. The text can be of variable length ranging from sentences to documents. . The vector representation is trained to be useful for predicting words in a paragraph. paragraph vector is concatenated with several word vectors from a paragraph and predicts following word in given context. Both word vector and paragraph vectors are trained by stochastic gradient descent with back propagation. paragraph vectors are unique among paragraph while word vectors are shared. At prediction time paragraph vectors are inferred by fixing word vectors and training the new paragraph vector until convergence. . Paragraph vector is capable of constructing representations of input sequences of variable length. It is applicable for text of any length from sentences, paragraphs to documents. . Algorithm . Word vectors are the inspiration for paragraph vectors. Every word is mapped to a unique vector represented by a column in a matrix W. The column is indexed by position of the word in vocabulary. The concatenation or sum of the vectors is then used as a feature for prediction of the next word in a sentence. Given a sequence of training words w1,w2,w3,.. wt. Objective of the word vector model is to maximize the average log probability. Prediction is done via a multiclass classifier such as softmax. Neural Network based word vectors are usually trained using stochastic gradient descent and back propagation. Once the training is converged, words with similar meaning are mapped to a similar position in the vector space. . Paragraph Vectors - are very much similar to word vectors. Word vectors are asked to contribute to the prediction task about the next word in the sentence. Hence even though word vectors are initialized randomly they eventually capture semantics as an indirect result of prediction task. the paragraph vector and word vector are averaged or concatenated to predict the next word in a context. The only change when compared to word vector framework is where h is constructed from W and D. This model is called Distributed Memory model of Paragraph Vectors (PV-DM) as the paragraph vector remembers what is missing from the current context of the paragraph. . The contexts are fixed- length and sampled from a sliding window over the paragraph. The paragraph vector is shared across all the contexts but not with all paragraphs. But the word vector matrix is shared across all the paragraphs. .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2019/01/10/Doc2Vec-Paper.html",
            "relUrl": "/markdown/2019/01/10/Doc2Vec-Paper.html",
            "date": " • Jan 10, 2019"
        }
        
    
  
    
        ,"post11": {
            "title": "Facebook Prophet Library",
            "content": "Literature Review of Facebook Prophet Library for Time series Analysis . So for people like me who loves to watch an explanation before diving deep into a paper, i would suggest this simple but powerful intro to fbprophet library. Fortune-Telling with Python: An Intro to Facebook Prophet. . The next important article that i religiously went through was the release article mentioned in research fb blog. Prophet - Forecasting at Scale. Some very important parts are discussed at length in this blog about the functionalities of FB prophet. . Prophet is an Additive regression model with 4 main components. . A piece wise linear or logistic growth curve trend. Prophet automaticaly detect changes in trends by selecting change points from the data. . | A yearly seasonal component modelled using Fourier series. . | A weekly seasonal component using dummy variables. . | A user provided list of important holiday. . | . So after a little bit of research about introductory blogs and videos its time to look into the research paper of facebook-prophet it is available in this link facebook-prophet. . Introduction - talks about the importance of forecasting, time required for an analyst to become an expert forecaster, how fb prophet helps an analyst in his forecasting tasks. Fb-prophet intends to use the analyst in the loop approach where the model can be adjusted through various analyst friendly parameters. . Features of Business Time Series - Seasonal effects are visible in a time series, there might be a weekly cycle, yearly cycle, or a vacation based cycle. seasonal effects naturally arises and can be expected in a time series generated by human actions. . Prophet Forecasting Models - Forecasts are made at three points in the history using only portion of the time series up to that point. Forecasts for each day are grouped and coloured by day of the week to visualize weekly seasonality. A Decomposible time series with 3 main model components are trend, seasonality and holidays. They are combined to an equationy(t)=g(t)+s(t)+h(t)+e where g(t) is the trend function, s(t) is the seasonality, h(t) is the holiday . The formula looks very much similar to a Generalized Additive Model. . Here we have time as regressor with nonlinear functions of time as components. The GAM formulation has the advantage that it is easy to decompose and easy to accommodate components easily. Time series problem is considered as a curve fitting exercise instead of identifying the temporal dependence structure of the time series data. . Trend Modelling - trend can be a saturating growth model and piece wise linear model. . Saturating growth model is typically modelled using a logistic growth model with a time varying factor ‘capacity’. we incorporate trend changes in growth model by explicitly defining changepoints where growth rate is allowed to change. | Similarly for linear piece wise model, a linear equation which changes withrespect to a time varying capacity and change points is formulated. | . Changepoint Selection - changepoints could be specified by the analyst (as a parameter -list of change point dates). the list affects the trend and induces a change in trend. . Trend Forecast Uncertainty - when the model is extrapolated past the history to make a forecast, the trend will have a constant rate. uncertainities are induced into the model by extending the Generalized additive model. the future will see same average frequency and magnitude of rate changes. . Seasonality - Due to human behaviour business time series often have multi period seasonality. Fourier transform is used to capture the seasonality. the parameters required to fit a fourier transform is obtained by constructing a matrix of seasonality vector for each value of t. . Holiday and Events - They provide predicatable shocks in most real world time series analysis. this is kept as a parameter where any analyst could pass the list to create a model which looks into the seasonality factor. . Model Fitting - so once seasonality, holiday features for each observation are combined into a matrix X and change point indicators a(t) in a matrix A, the entire model can be expressed in a few lines of Stan Code. The Stan actualy provides an easy interface to perform probablistic calculations like penalized maximum likelihood function(L-BFGS), approximate Bayesian inference with variational inference, etc. Prophet uses decomposable model and allows us to look at each component of the forecast separately. . Analyst in Loop Modeling - Analyst can alter the model to apply there expertise and external knowledge with limited statistical knowledge. . Capacity - analyst may have the external data for market size and can apply that knowledge directly by specifying capacities. | Changepoints - Analyst might know about certain shock days where abnormal values might come up. this can be directly specified. | Holidays and Seasonality - Holidays and seasonalities could be specifically mentioned. | Smoothing Parameters - By adjusting the smoothing parameter an analyst can select from a range of more global or locally smooth models. | . The effort of the analyst could help in including judgemental and statistical forecasting and we can have a balance of both. . Automating the Evaluation of Forecast . By use of baseline forecast - simplistic forecast is used to compare a set of baseline methods. | Modelling Forecast Accuracy - Forecast is made over a certain days like 90,180 days etc. | Let y(t) | .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/16/Literature-Review-FB-Prophet.html",
            "relUrl": "/markdown/2018/11/16/Literature-Review-FB-Prophet.html",
            "date": " • Nov 16, 2018"
        }
        
    
  
    
        ,"post12": {
            "title": "Introduction to TensorFlow",
            "content": "Tensorflow -1 . So Hi, Again I’m trying to start fresh with Tensor Flow Basics - but this time with more code. I’ll be almost copy pasting the code (best way to learn is to first copy, understand and then refactor, as per my way). . Exercise - 1) Hello World! . Simple straight forward Hello World in TensorFlow . import tensorflow as tf hello = tf.constant(&quot;Hello World!&quot;) sess = tf.Session() sess.run(hello) ##-&gt; Output - b&#39;Hello World!&#39; . Exercise - 2) Basic Operations with Constant . So important things . we are opening a tf.Session() as sess and the indentation is important it means the sess is not closed. | we use the python string formating to print sentences {} are just part of that. don’t get tensed it is simple. request you to look into W3 schools to learn more about string formating. i Just did now and it was a great learning. :) | . a = tf.constant(5) b = tf.constant(4) with tf.Session() as sess: print(&quot;Constant a = {} nConstant b = {}&quot;.format(sess.run(a),sess.run(b))) print(&quot;Addition a + b = {}&quot;.format(sess.run(a+b))) print(&quot;Multiplication a*b = {}&quot;.format(sess.run(a*b))) print(&quot;Subtraction a-b = {}&quot;.format(sess.run(a-b))) print(&quot;Division a/b = {}&quot;.format(sess.run(a/b))) ##-&gt; Output #Constant a = 5 #Constant b = 4 #Addition a + b = 9 #Multiplication a*b = 20 #Subtraction a-b = 1 #Division a/b = 1.25 . Exercise - 2) Basic Operations with Variables . lets do the above exercise with variables now. . a = tf.variable(tf.int16) b = tf.variable(tf.int16) add = tf.add(a,b) mul = tf.multiply(a*b) with tf.Session() as sess: print(&quot;Addition of Variables - {}&quot;.format(sess.run(add,feed_dict = {a:10,b:5}))) print(&quot;Multiplication of Variables - {}&quot;.format(sess.run(mul,feed_dict = {a:10,b:5}))) ##-&gt; Output #Addition of Variables : 15 #Multiplication of Variables : 50 . Exercise - 3) Matrix Multiplication . This is a straight forward example of matrix multiplication. please make sure the shape of the matrix is correct else chances of running into some shape error. . mat1 = tf.constant([[3,3]]) mat2 = tf.constant([[2],[2]]) result = tf.matmul(mat1,mat2) with tf.Session() as sess: print(&quot;Matrix Multiplication of ([3,3]) and ([2],[2]) = {}&quot;.format(sess.run(result)) #-&gt; Output # Matrix Multiplication of ([3,3]) and ([2],[2]) = [[12]] . Exercise - 4) Eager Execution . This is a relatively new paradigm in tensorflow programming. in eager execution mode we can do away with graph or interestingly we don’t have to start a session to do tensorflow computations. This idea is actually borrowed from the main competitor of tensorflow - pytorch. lets code it. . import tensorflow as tf print(&quot;Setting Eager Mode&quot;) tf.enable_eager_execution() print(tf.executing_eagerly()) #-&gt;Output # Setting Eager Mode # True . My Observations . Eager Execution should be enabled at the start of the program, If you are in the middle of a Jupyter notebook i request you to open a new notebook for this exercise, else it will throw an error message. I hope the next version of tensorflow (tensorflow 2.0) would fix this issue and eager execution will be the default setting. | . Lets get back to code. . a = tf.constant(5) b = tf.constant(10) print(&quot;Tensor Constant a : {}&quot;.format(a)) print(&quot;Tensor Constant b : {}&quot;.format(b)) print(&quot;Tensor Constant a+b : {}&quot;.format(a+b)) #-&gt; Output # Tensor Constant a : 5 # Tensor Constant b : 10 # Additon of Tensor constant a+b : 15 . Observations . We now have sessions. | The Code now looks more pythonic | . import numpy as np a = tf.constant([[2,3],[2,4]],dtype=tf.float32) b = np.array([[1,2],[3,2]],dtype=np.float32) print(&quot;Addition : {}&quot;.format(a+b)) print(&quot;Subtraction : {}&quot;.format(a-b)) print(&quot;Multiplication : {}&quot;.format(a*b)) #-&gt;Output #Tensor Additon - [[3. 5.] # [5. 6.]] #Tensor Subtraction- [[ 1. 1.] # [-1. 2.]] #Tensor Multiplication- [[2. 6.] # [6. 8.]] .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/15/TensorFlow-Basics-(Github-tutorial-Ayemeric-2).html",
            "relUrl": "/markdown/2018/11/15/TensorFlow-Basics-(Github-tutorial-Ayemeric-2).html",
            "date": " • Nov 15, 2018"
        }
        
    
  
    
        ,"post13": {
            "title": "NER with Bidirectional LSTM and CNN",
            "content": "Named Entity Recognition with Bidirectional LSTM-CNNs by Jason P.C. Chiu and Eric Nichols. . Reference for the Paper - Named Entity Recognition with Bidirectional LSTM - CNN by Jason P.C.Chiu and Eric Nichols. . Github Reference - . Introduction - Named entity recognition (NER) is an important part in NLP and has been dominated by applying CRF, SVM or Perceptron models to hand crafted features. . Collobert et al. (2011b) - proposed idea of word embedding trained on large quantity of unlabelled text data with an effective neural network and a little feature engineering. However this doesn’t work well with rare words or words that are poorly embedded, hence a new powerful neural network model is needed. RNN’s (1996 - Goller and Kuchler) are popular since 2013 for machine translation and language modelling. | LSTM unit with forget gate improves long term dependencies to be easily learned (Gers et al - 2000). | For Labelling task like NER and speech recognition a bi directional LSTM model can take into account infinte amount of context that applies to any feed -forward model. | CNN was investigated for modelling character level information among other NLP tasks. | . | hence, a hybrid model involving CNN and bi directional LSTM that learns both character level and word level features presenting the first evaluation of such an architecture on well established english language evaluation datasets. | Lexicons are considered important for NER performance, hence a new lexicon encoding scheme and matching algorithm that can make use of partial matches and compare it to simpler approach of Collobert. | . Model . In Collobert’s model, lookup tables transforms discrete features such as words or characters into continous vector representation, which are then concatenated and fed into a neural network. Here instead of feed forward network, a Bidirectional LSTM network is used. To induce character level features a convolutional neural network is used. . | Sequence Labelling with LSTM - A stacked bi-directional recurrent neural network with long short term memory units are used to transform word features into named entity tag scores. The extracted features of the word are fed into a forward LSTM network and a backward LSTM network. The output of each network at each time step is then decoded by a linear layer and a log softmax layer into log probabilities for each tag category. These two vectors are simply added to get the final output. This architecture was found to be the best effective one after minor experiments. . | Extracting Character Features using CNN - For each word a convolution and a max layer to extract a new feature vectors such as character embedding and character type. Words are padded with number of special padding characters on both sides depending on the window size of CNN . | Word Embedding - the best model used the publicly available 50 dimensional word embedding released by Collobert which were trained on Wikipedia and Reuters Dataset that are publicly available. all words were lower cased before passing through the lookup table to convert the word embedding. the pretrained embedding was allowed to be modified during training. . | Character Embedding - We randomly initialized a lookup table with values drawn from a uniform distribution with a range [-0.5 , 0.5] to output a character embedding of 25 dimensions. The character set includes all unique characters in CoNLL-dataset plus the special token paddings and unknown. . | Capitalization - Collobert’s method of using separate lookup table to add for a capitalization feature with options, All Caps, Upper Initial, lowercase, mixed case and no info. . | Lexicons - lexicons were categorised into 4 categories (‘Person’,’Organisation’,’Location’,’Misc’). For each lexicon category, it matched every n-gram against entries in the lexicon, A match is successful when the ngram matches the prefix or suffix of an entry and is atleast half the length of the entry. For all categories except Person, partial matches less than 2 token in length were discarded. when multiple overlaps are there maximum matched category is considered. matches are case insensitive. Each category is BIOES (begin, inside, outside, end, single) encoded. The best model used SENNA Lexicon (by Collobert et al) with exact matching and DBpedia lexicon with partial matching with BIOES annotation in both cases. . | Character Level features - A lookup table was used to output a 4 dimensional vector representing the type of the character. . | . Training and Inference Implemented using torch7 library (LUA). Training and inference were done on a per sentence level. Initial states of the LSTM are zero vectors. Except for the character and word embeddings whose initialisation were described previously. all lookup tables were also randomly initialised. . Objective function and Inference . [Requesting to go through the paper as i couldn’t comprehend and write here in the blog post] . Tagging Scheme - BIOES tagging scheme was used. . Learning Algorithm - Training done by minibatch SGD with a fixed learning rate. Each batch consists of multiple sentences with same number of tokens. Applied dropout to the output nodes of each LSTM layer to reduce overfitting. Other optimization algorithms like momentum, ada delta, RMSProp, were considered but SGD appears to perform well. . Evaluation - Evaluation was performed CoNLL-2003 NER shared dataset. . Dataset Preprocessing . All digit sequence are replaced by single 0. | Before training, Sentences were grouped by word length into mini batches and shuffled. | . Dataset - . CoNLL-2003 dataset consists of newswire from Reuters corpus tagged with four types of named entities : location, organization, person and miscellaneous. Dataset is small hence model has been trained on both training and development sets after performing hyper parameter optimization. | OntoNotes Dataset - Pradhan et al compiled a core portion of OntoNotes dataset for the CoNLL-2012 shared task and described a standard train/test/dev split which was used for evaluation. This dataset is much larger and has text from variety of sources. | . Hyper parameter Optimisation . Two rounds of hyper parameter optimisations were done and selected based on development set performance. Over 500 hyper parameter setting were evaluated and then the same setting was taken along with learning rate to OntoNotes dataset. . | for second Round - Independent hyper parameter searches on each dataset were carried out using Opportunity’s implementation of particle swarm (better than random search). Over 500 hyper parameters were again searched this round - training failed occasionaly and gave large variations from run to run. hence top 5 setting were taken and 10 trials were done and selected the best which gave the best average performance. . | For CoNLL particle swarm produced best hyper parameters however for OntoNotes it didnot perform well. . | CoNLL model was trained for large number of epochs as the no sign of overfitting was observed. Contrary training on Onto Notes began to overfit after 18 epochs. . | . Excluding Failed Trials . On CoNLL dataset BiLSTM model completed training without any difficulty, the BiLSTM-CNN model failed upto 10-15% of trials depending on the feature set. in OntoNotes it failed upto 1.5% trials. Using lower learning rate reduces the failure rate. Gradient Clipping and AdaDelta were effective in eliminating failures, however AdaDelta made training expensive. The threshold for CoNLL dataset was 95% and OntoNotes was 80% . . Training and Tagging Speed . on Intel Xeon E5-2697 processor training takes about 6 hours while tagging takes about 12 seconds for CoNLL dataset. For OntoNotes dataset it was 10 hours and 60 seconds respectively. . Results and Discussion . Given enough data the neural network automatically learns the relevant features for NER without feature engineering. . Comparison with FFNN by Collobert. Colloberts FFNN model was reinvented and compared with the BiLSTM model. FFNN was the baseline for comparison. FFNN was clearly inadequate for OntoNotes which proved that LSTM is required for a larger domain for NER. . Character Level CNN’s vs Character type and Capitalisation Features . BiLSTM -CNN models outperforms BiLSTM model significantly when given same feature set. | The effect is not statistically significant on OntoNotes when capitalisation features are added. | Character level CNN can replace handcrafted character features in some cases. When trained word embeddings were used large significant improvements were noted instead of random embedding regardless of additional features. | 300 dimensional embedding present no significant improvement over 50 dimensional embedding | gloVe embedding improved significantly over publicly available embeddings on CoNLL and word2vec skipgram embedding improved significantly over google’s embedding on OntoNotes. | . Effect of DropOuts . Dropouts are essential for state of the art performance and improvement is statistically significant. DropOut is optimized on the devset, hence the chosen value may not be best performing. . Lexicon Feature . CoNLL using features from both SENNA lexicon and proposed DBpedia lexicon provides a significant improvement which is suspected to be because both the lexicons are complementary, SENNA lexicon is clean while DBpedia lexicon is noisy with higher coverage. . Analysis on Onto Notes Performance . Model performs best on clean text like broadcast news (BN) and newswire(NW) and worst on noisy text like telephone conversation and webtext. The model also substantially improve except for telephone conversation. . Related Research . Recent approaches in NER has came from CRF, SVM and perceptron models performance is heavily dependent of feature engineering. k means clustering over a private database of search engine query logs instead of phrase features helped to achieve 90.8% in CoNLL dataset. large scale unlabelled data was used to perform feature reduction this inturn acheived an F1 Score or 91.02%. | Training an NER system with entity linking has proved to be a success. | NER with Neural Networks - many approaches involve CRF model. However now we have computational power available hence complex neural networks are now being investigated for Neural Networks. CharWNN network augments neural network of Collobert with characterlevel CNN’s and reported improved performance on Spanish and Portugeese NER. | BiLSTM has been used for POS tagging, chunking and NER task with heavy feature engineering instead of using CNN to extract character level features | BiRNN with character level CNN’s to perform German POS tagging is successfull | Both word and character level BiLSTM has been used to create the current state of the art English POS tagging, Using BiLSTM instead of CNN allows for extraction of more sophisticated character level features but for NER it didnot perform significantly better than CNN and was computationaly expensive | . Conclusion . Neural Network model with Bidirectional LSTM and character level CNN benefits from robust training through dropout , achieved state of the art results in Named Entity Recognition with little feature engineering. .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/10/LiteratureReview-Named-Entity-Recognition-using-BIdirectional-LSTM.html",
            "relUrl": "/markdown/2018/11/10/LiteratureReview-Named-Entity-Recognition-using-BIdirectional-LSTM.html",
            "date": " • Nov 10, 2018"
        }
        
    
  
    
        ,"post14": {
            "title": "Implementing RNN / LSTM in Tensorflow",
            "content": "Implementing RNN / LSTM in Tensorflow . So i started learning about LSTM and RNN through Christopher Olah’s blog about the same. Please find it here - http://colah.github.io/posts/2015-08-Understanding-LSTMs . It gives a great intuitive understanding about the topic that I’m trying to implement. . so lets start with some dummy data - . Input Data - At time step t, X_t has a 50% chance of being 1 (and a 50% chance of being 0). E.g., X might be [1, 0, 0, 1, 1, 1 … ]. | Output Data - At time step t, Y_t has a base 50% chance of being 1 (and a 50% base chance to be 0). The chance of Y_t being 1 is increased by 50% (i.e., to 100%) if X_t - 3 is 1, and decreased by 25% (i.e., to 25%) if X_t - 8 is 1. If both X_t - 3 and X_t − 8 are 1, the chance of Y_t being 1 is 50% + 50% - 25% = 75%. | . Lets generate this data in python . import numpy as np import tensorflow as tf %matplotlib inline import matplotlib.pyplot as plt def gen_data(size=1000000): X = np.array(np.random.choice(2, size=(size,))) Y = [] for i in range(size): threshold = 0.5 if X[i-3] == 1: threshold += 0.5 if X[i-8] == 1: threshold -= 0.25 if np.random.rand() &gt; threshold: Y.append(0) else: Y.append(1) return X, np.array(Y) def gen_batch(raw_data, batch_size, num_steps): raw_x, raw_y = raw_data data_length = len(raw_x) batch_partition_length = data_length // batch_size data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32) data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32) for i in range(batch_size): data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)] data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)] epoch_size = batch_partition_length // num_steps for i in range(epoch_size): x = data_x[:, i * num_steps:(i + 1) * num_steps] y = data_y[:, i * num_steps:(i + 1) * num_steps] yield (x, y) def gen_epochs(n, num_steps): for i in range(n): yield gen_batch(gen_data(), batch_size, num_steps) .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/10/Literature-Review-RNN-and-LSTM-implementation-in-Tensor-Flow.html",
            "relUrl": "/markdown/2018/11/10/Literature-Review-RNN-and-LSTM-implementation-in-Tensor-Flow.html",
            "date": " • Nov 10, 2018"
        }
        
    
  
    
        ,"post15": {
            "title": "Tensorflow Basics",
            "content": "Tensorflow -2 . So this is my attempt to learn the very basics of tensorflow. I’m currently following a book Fundatmentals of Deep Learning by Nikhil Buduma. It is available in the public domain and provides an excellent intuition of neural networks in TensorFlow. I’ve been trying to master TensorFlow for previous couple of weeks and i decided to start with a book rather than learning online. . Thankfully I’m an expert in installing tensorflow in Anaconda i’ve done it multiple times. lets start with the next basic step. . Import tensorflow . import tensorflow as tf # This import tensorflow with tf as an alias. . Hello World . let’s print ‘hello World’ in tensorflow . import tensorflow as tf helloWorld= tf.constant(&#39;Hello World&#39;) sess = tf.session() session.run(helloWorld) -&gt; &#39;Hello World&#39; . bit length when compared to python. Interestingly as per latest tensor flow version, we have something called eager execution where in we can do away with tf.Session() . Constants . import tensorflow as tf tf.enable_eager_execution() const=tf.constant(&#39;Hello World&#39;) print(const) -&gt;tf.Tensor(b&#39;Hello World&#39;, shape=(), dtype=string) . I’m still learning the nuances of tensorflow enable_eager execution. I shall write more on this when i have a clear picture about it. lets go back to the graph and sessions paradigm once again. . a = tf.constant(2) b = tf.constant(3) mul = tf.multiply(a,b) session.run(mul) -&gt; 6 . Variables . Variables must be explicitly initialized before a graph is used for the first time | Gradient Method could be used to modify the variables after each iteration | We can save values stored in variables to disk and restore them for later use. | . weights = tf.Variable(tf.random_normal([300,200],stddev=0.5), name=&#39;weights&#39;, trainable=False) . tf.random_normal is an operation that produce a tensor initialised using a normal distribution with standard deviation of 0.5, we could use other initializers as well they are . tf.zeros(shape, dtype=tf.float32) tf.ones(shape, dtype=tf.float32) tf.random_normal(shape, dtype=tf.float32,mean=0, stddev=1,seed=0) tf.truncated_normal(shape, dtype=tf.float32,mean=0, stddev=1,seed=0) tf.random_uniform(shape, dtype=tf.float32,mean=0, stddev=1,seed=0) . | tensor shape is 300x200, implying weights connect a layer with 300 neurons to a layer with 200 neurons . | we have also passed a name to the variable ‘weights’ . | trainable = True /False lets the tensorflow know that if the weights are meant to be trainable. . | .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/09/TensorFlow-Basics.html",
            "relUrl": "/markdown/2018/11/09/TensorFlow-Basics.html",
            "date": " • Nov 9, 2018"
        }
        
    
  
    
        ,"post16": {
            "title": "Tensorflow Basics-3",
            "content": "Tensorflow -3 . So Hi, Again I’m trying to start fresh with Tensor Flow Basics - but this time with more code. I’ll be almost copy pasting the code (best way to learn is to first copy, understand and then refactor, as per my way). . Exercise - 1) Hello World! . Simple straight forward Hello World in TensorFlow . import tensorflow as tf hello = tf.constant(&quot;Hello World!&quot;) sess = tf.Session() sess.run(hello) ##-&gt; Output - b&#39;Hello World!&#39; . Exercise - 2) Basic Operations . So important things . we are opening a tf.Session() as sess and the indentation is important it means the sess is not closed. | we use the python string formating to print sentences {} are just part of that. don’t get tensed it is simple. request you to look into W3 schools to learn more about string formating. i Just did now and it was a great learning. :) | . a = tf.constant(5) b = tf.constant(4) with tf.Session() as sess: print(&quot;Constant a = {} nConstant b = {}&quot;.format(sess.run(a),sess.run(b))) print(&quot;Addition a + b = {}&quot;.format(sess.run(a+b))) print(&quot;Multiplication a*b = {}&quot;.format(sess.run(a*b))) print(&quot;Subtraction a-b = {}&quot;.format(sess.run(a-b))) print(&quot;Division a/b = {}&quot;.format(sess.run(a/b))) ##-&gt; Output #Constant a = 5 #Constant b = 4 #Addition a + b = 9 #Multiplication a*b = 20 #Subtraction a-b = 1 #Division a/b = 1.25 .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/09/TensorFlow-Basics-(Github-tutorials-by-Aymeric).html",
            "relUrl": "/markdown/2018/11/09/TensorFlow-Basics-(Github-tutorials-by-Aymeric).html",
            "date": " • Nov 9, 2018"
        }
        
    
  
    
        ,"post17": {
            "title": "NER using Neural Networks",
            "content": "Literature Review of Named Entity Recognition using Neural Networks . This is a short literature review of the detailed study conducted by Fabian Karl on the topic of Named Entity Recognition, the complete paper is available in this link : Independent Study by Fabian Karl (University of Hamburger). . Named Entity Recognition - in simple words it is the task of finding or recognising named entities from a text / corpus. Named Entity could be anything from a person, organisation, Location or anything of that sort which are of interest to the user. The goal of the study is to replicate the state of the art performance in NER without any handcrafted rules but only using pre labelled training data. . Dataset Used - two labelled data collection were used for training and testing . CoNLL-2003 - English and German | GermEval-2014 Dataset | . Neural Network . Recurrent Neural Network - RNN’s get a sequence of features as input where each feature could stand for one time step of some process, However RNN has a serious flaw of Exploding / vanishing gradient. because of which we have considered LSTM cells which are modified RNN. Major characteristic of LSTM cell is the various kind of forget gates. LSTM are widely used in Named Entity recognition. | Convolutional Neural Network - CNN connects only a certain number of nodes to one of its preceding nodes where in a regular feed forward neural network connects to a certain number of nodes to one of its preceding nodes. CNN’s are state of art network for image recognition tasks. | Conditional Random Fields - An additional conditional random field CRF instead of last softmax layer of one of the previously described neural networks allows to take the context of the output tags into account. Hence it can make predictions about the out coming tags on the basis of the whole output sequence. | . Methods . Creating a numeric representation of textual input is essential in NLP for embedding it into a vector representation. . One-Hot encoding is the best and easiest way to encode everything that is present. However this method has its own drawbacks, results in n vectors of size n (number of words) and has no meaningful representation . | Embed each word based its context First they are one Hot encoded and trained on on their context of words with one hidden layer. This allows for a meaningful comparison between vectors. this method allows to embed vectors into smaller vectors eg- 300 size vectors. . | Fasttext Model - it is a pretrained model that uses continuous word representations instead of discrete representations of every word. Here a a vector representation is associated to each charater n grams with words being the sum of these representation. . | Word2vec and BPEmb - They performed worse than Fasttext model . | . Bi Directional Context . In order to take context information into account when predicting the tag of a word, the words before and after the word in question were also embedded and used as an additional information. The sentence was split into two lists where the first list contained all the embedding of word from the beginning of the sentence until the word in question inclusive, second list contains all the embeddings from the last word to the word in question. . Model Architecture . A modified Bi LSTM neural-net was used. After embedding 2 LSTM networks with 300 cells were added to the model, they were concatenated and result was fed to into 3 connected dense layer with 300 , 100 and 9 units respectively with a dropout of 0.6. If the CRF layer was not used, the Softmax activation function was applied for the last layer. ReLU activation was used for all the other layers. If CRF function was used in the last layer then ReLU was used instead of softmax. The last layer was then reshaped into a sequence length of 1 and given into CRF layer which returned a one hot encoding over the nine output categories. The architecture resulted in having around 1.7 million trainable parameters. Batch Size was set to 512 for all the experiments without CRF and 300 for all others. . Character Embedding . The word is converted into characters and the ASCII representation is saved into a List. This List is reversed and used as separate input into the dense layer and then concatenated with the first drop-out layer after concatenation of the two LSTM layers. . CNN instead of LSTM . This was the second architecture they had experimented with. Two LSTM layers were replaced by number of convolutional layers spanning over different number of words. Each convolutional layer consists of fixed number of convolutional filters, each spanning over a matrix of 300*n . The idea is to use multiple smaller filters in order to capture spacial and local information. . Other Related Works . Here the aim of the study was to replicate the state of the art behaviour for the NER task. Hence elements of the neural network architecture of other proven studies were taken into consideration. Use of Bi LSTM with CRF layer and character embedding had a performance score of 90.94 on english and 78.76 on german which were significant improvement at those current standards. . Discussion . Character Embedding - the results showed that when using a char representation of the word in question next to the bidirectional embedding of the whole sequence with a pretrained fasttext word embedding model gives the best performance. The fasttext embedding has a slight disadvantage that it converts all the Upper case letters to lowercase before reading it. . | Conditional Random Field - CRF conditions showed inferior performance than softmax layer. a good explanation couldnot be found for this. Hyper parameter tuning was not systemic that could be a valid reason why it didn’t perform well. . | . Conclusion . This proves the capabilities of neural architectures to learn tagging task (and categorisation tasks) with no external knowledge needed. It also shows that the importance and performance of neural network architectures for natural language tasks will further increase in the future .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/09/LiteratureReview-Named-Entity-Recognition.html",
            "relUrl": "/markdown/2018/11/09/LiteratureReview-Named-Entity-Recognition.html",
            "date": " • Nov 9, 2018"
        }
        
    
  
    
        ,"post18": {
            "title": "TensorFlow Basics",
            "content": "Tensorflow -4 . So this is the last chapter of walk through of the concepts that i have tried to learn in past 5 days about tensorflow. There are 4 highlevel API’s that were introduced in the latest version of TensorFlow (1.9 as on 10-31-2018). lets discuss about third of those 4 high level API’s, we have already coverd tf.keras, EagerExecution and Importing Data previously. lets look into Estimators perhaps the most important one.! . Estimators . tf.estimator is a highlevel TensorFlow API that is meant to simplfy machine learning programming. estimator encapsulate the following actions, Training, Evaluation, Prediction, Export for serving .We can either use the pre-made estimators or we can write custom estimators based on the tf.estimator.Estimator class. . Summary of white paper published by Google. . Why we need estimators ? - The paper discuss about the natural tension between flexibility and simplicity with robustness. DSL based model architecture (Domain Specific Language) helps in making coming up with machine learning models that are simple and highly robust however with very less flexibility. DSL systems are hard to maintain as the research is still advancing in a rapid pace. This lead to the development of TensorFlow. . Estimator framework described in this paper is implemented on top of tensorflow which provides an interface similar to Scikit-learn with some adaptation for productionization. Preference for functions and closures over objects. callbacks are common in closures. Layer functions are tensor in tensor out operations. . Various Components of Estimator . Layers - A layer is simply a reusable part of code, and can be as simple as a fully connected neural network layer.layers are implemented as free functions, taking Tensors as input arguments and returning Tensors. . Estimator -The interface for users of Estimator is loosely modeled afer Scikit-learn and consists of only four methods: train - trains the model, given training data, evaluate - computes evaluation metrics over test data, predict- performs inference on new data given a trained model, and export_savedmodel - exports a SavedModel. Estimator hides the tensorflow concepts like Graph and session from the user. . Canned Estimator - There are many model architectures commonly used by researchers and practitioners. We decided to provide those architectures as canned Estimators so that users don’t need to rewrite the same models again and again. .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/02/TensorFlow-Learning-Estimators.html",
            "relUrl": "/markdown/2018/11/02/TensorFlow-Learning-Estimators.html",
            "date": " • Nov 2, 2018"
        }
        
    
  
    
        ,"post19": {
            "title": "Loading PDF Data to Python",
            "content": "Tensorflow -5 . So getting back to something very much in use from a business angle. Often we are left with a whole directory of PDF files and as Data scientist our job might be to extract usefull information from this pile of documents. Our first aim would be to find a good library or code snippet that would help us to extract pdf into python. Below is the list that i compiled after a quick couple of hours of search in internet. . pyPDF2 module | textract | tika package | pdftotext | tesseract | python-Docx | pdfminer | . Lets look into how to use each library . pyPDF2 - this blog post helped me with the initial code structure to extract pdf pyPDF2 sample code. . this is a decent library with good resources to start around, but i’m yet to figure out a way to get all the texts in a python list format a bit more research is needed. I would get back to this library if i’m running out of luck with all the other libraries. . textract - i just ran out of luck in the very first step which is installing the library. it threw some dependency error, I figured out that this repo is not being updated for quite some time. I still tried to install it by manually installing dependencies but without much luck. so after a good half an hour of research i decided to move on. . tika package - this is the best python library for extracting text from PDF. i referred this blog post for getting my head around this library Tika extract PDF. as per my preliminary research this appears to be the best library for extracting text from PDF. I tried the code locally and it did work so very much happy with tika. . I thought of looking through other libraries just to know how good they are after all i should be utilising my time to research on this topic. . pdfToText from xpdf - so i think this is more of a standalone tool instead of a ready to use library. i tried to install the python library but not much resources are available in the open forum. i spend quite an awfull lot of time to install it correctly but again no luck. . Tesseract - This is a very promising library a wrapper around the googles Tesseract OCR engine. This should be great for images and i found quite a lot of interesting tutorials on how to read characters from image using tesseract but extracting pdf looks a bit tough, i couln’t figure out a working code snippet to do this, perhaps it may be hidden. anyways i’ll be considering this library if tika fails. Tesseract is very promising because of the number of people who have successfully used it to rad characters from image. . Python-Docx - Again this one also looks like a standalone tool i tried installing the library but to my bad luck i couldn’t get this library to work for me it is also throwing some dependency error and when i traced it back i met with dead end. i couldnt find the github repository itself in github. . PDF-Miner - This one was a straight 2 minutes quick installation and and short tutorial mentioned in stack overflow post link to the question in stackoverflow. This one saved quite a lot of time. . So my Final Pick is Tika, PDF Miner, pyPDF2 and then tesseract. Next step is to test the efficiency of PDF to text extraction. .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/02/PDFtoText-Extractor-Python-3.html",
            "relUrl": "/markdown/2018/11/02/PDFtoText-Extractor-Python-3.html",
            "date": " • Nov 2, 2018"
        }
        
    
  
    
        ,"post20": {
            "title": "TensorFlow-3",
            "content": "Tensorflow -6 . So this is a walk through of all the concepts that i have tried to learn in past 3 days about tensorflow. There are 4 highlevel API’s that were introduced in the latest version of TensorFlow (1.9 as on 10-31-2018). lets discuss about third of those 4 high level API’s, we have already coverd tf.keras, EagerExecution previously. lets look into Importing Data. . Importing Data . Here our aim is to build a robust data Pipeline and Tensorflow has came up with tf.data API to enable us build complex input pipelines from simple reuseable pieces. tf.data helps us to make it easy to deal with large amount of data, different format of data with complicated transformation. . tf.data API introduces two new abstractions to tensorflow : . tf.data.Dataset - to represent a sequence of element, in which each element contain one or more Tensor object. two important methods that could be put to use are tf.data.Dataset.from_tensor_slices( - to construct a dataset from one or more tf.Tensor objects. . tf.data.Dataset.batch() helps us to apply transformation on tf.data.Dataset object. . Next method is tf.data.Iterator - it provides the main way to extract elements from a dataset. The operation returned by Iterator.get_next() yields the next element of a Dataset when executed and acts as an interface between input pipeline code and model. . Fundamentals of Creating a Dataset and Iterator objects . For a input data pipeline we need to have a source defined if the source is in tensor format then tf.data.Dataset.from_tensors() or tf.data.Dataset.from_tensor_slices() could be used. instead if the data is in disk in the recommended TFRecord format we can use tf.data.TFRecordDataset method. Once the Dataset object is ready we can transform it into a new Dataset by chaining method calls on the tf.data.Dataset object. Elemental transformation on this Dataset object could be done using Dataset.map and multi element transformation could be carried out using Dataset.batch(). As mentioned earlier we make use of tf.data.Iterator for consuming values from Dataset object. tf.data.Iterator has two important methods namely Iterator.initializer to reinitialize iterator state and Iterator.get_next() to get the next element or next batch of element from the dataset. . Dataset Structure . A dataset comprises of elements that each have the same structure. An element contains one or more tf.Tensor object called components and each component has a tf.DType representing the type of the elements in the tensor and a tf.TensorShape representing the the static shape of each element. lets dive into code rather than explaining here. . dataset1 = tf.data.Dataset.from_slices(tf.random_uniform([4,10])) print(dataset1.output_types) # output -&gt; tf.float32 print(dataset1.output_shapes) # output -&gt; (10,) dataset2 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4]), tf.random_uniform([4,100], maxval = 100, dtype =tf.int32) print(dataset2.output_types) # output -&gt; (tf.float32, tf.float32) print(dataset2.output_shapes) # output -&gt; ((),(100,)) dataset3 = tf.data.Dataset.zip((dataset1,dataset2)) print(dataset3.output_types) # output -&gt; (tf.float32,(tf.float32, tf.float32)) print(dataset3.output_shapes) # output -&gt; (10,((),(100,))) . some examples of Dataset transformation function . dataset1 = dataset1.map(lambda x: ...) dataset2 = dataset1.flat_map(lambda x,y: ...) dataset3 = dataset1.filter(lambda x,(y,z): ...) . Creating an Iterator . there are multiple types of iterator namely, one-shot, initializable, reinitializable and feedable . One-Shot Iterator . dataset = tf.data.Dataset.range(100) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() for i in range(100): value = sess.run(next_element) assert i ==value . Initializable - iterator requires you to run an explicit iterator.initializer operation before using it. it enables us to parameterize the definition of the dataset, using one or more tf.placeholder() . max_value = tf.placeholder(tf.int64,shape=[]) dataset = tf.data.Dataset.range(max_value) iterator = dataset.make_initializable_iterator() next_element = iterator.get_next() sess.run(iterator.initializer, feed_dict = {max_value : 10}) for i in range(10): value = sess.run(next_element) assert i == value sess.run(iterator.initializer, feed_dict = {max_value : 100}) for i in range(100): value = sess.run(next_element) assert i == value . Reinitializable - A reinitializable iterator can be initialized from multiple different Dataset objects. like training dataset and validation dataset. These pipelines will typically use different Dataset objects that have the same structure. . # Define training and validation datasets with the same structure. training_dataset = tf.data.Dataset.range(100).map( lambda x: x + tf.random_uniform([], -10, 10, tf.int64)) validation_dataset = tf.data.Dataset.range(50) iterator = tf.data.Iterator.from_structure(training_dataset.output_types, training_dataset.output_shapes) next_element = iterator.get_next() training_init_op = iterator.make_initializer(training_dataset) validation_init_op = iterator.make_initializer(validation_dataset) for _ in range(20): # Initialize an iterator over the training dataset. sess.run(training_init_op) for _ in range(100): sess.run(next_element) # Initialize an iterator over the validation dataset. sess.run(validation_init_op) for _ in range(50): sess.run(next_element) . Feedable - Feedable gives us much more flexibility to choose from multiple iterators for each call to tf.Session.run. It offers all the functionality of reinitializable iterator but doesnot requires us to initialize the iterator from start of a dataset, while switching between iterators. . training_dataset = tf.data.Dataset.range(100).map(lambda x:x+tf.random_uniform([],-10,10,tf.int64)).repeat() validation_dataset = tf.data.Dataset.range(50) handle = tf.placeholder(tf.string, shape=[]) iterator = tf.data.Iterator.from_string(handle, training_dataset.output _types, training_dataset.output_shapes) next_element = iterator.get_next() training_iterator = training_dataset.make_one_shot_iterator() validation_iterator = validation_dataset.make_initializable_iterator() training_handle = sess.run(training_iterator.string_handle()) validation_handle = sess.run(validation_iterator.string_handle()) while True: for _ in range(200): sess.run(next_element, feed_dict = {handle: training_handle}) sess.run(validation_iterator.initializer) for _ in range(50): sess.run(next_element, feed_dict = {handle : validation_handle}) . Consuming Values from an Iterator . Iterator.get_next() method returns one or more tf.Tensorobjects that correspond to the symbolic next element of an iterator. Calling Iterator.get_next() does not immediately advance the iterator. Instead you must use the returned tf.Tensor objects in a TensorFlow expression, and pass the result of that expression to tf.Session.run() to get the next elements and advance the iterator. If the iterator reaches the end of the dataset, executing the Iterator.get_next() operation will raise a tf.errors.OutOfRangeError hence the best practice here is to use it inside a try except loop. . sess.run(iterator.initializer) while True: try: sess.run(result) except tf.errors.OutOfRangeError: break . Iterators in Complex Datasets - Consider a dataset as shown below (dataset3) each element of the dataset has a nested structure, the return value of Iterator.get_next() will be one or more tf.Tensorobjects in the same nested structure : . dataset1 = tf.data.Dataset.from_tensor_slices(tf.random_uniform([4, 10])) dataset2 = tf.data.Dataset.from_tensor_slices((tf.random_uniform([4]), tf.random_uniform([4, 100]))) dataset3 = tf.data.Dataset.zip((dataset1, dataset2)) iterator = dataset3.make_initializable_iterator() sess.run(iterator.initializer) next1, (next2, next3) = iterator.get_next() . Saving iterator state - tf.contrib.data.make_saveable_from_iterator() function creates a Saveable object from an iterator to save and restore the current state of the iterator or the whole input pipeline. this will be added to tf.train.Saver variables list or the tf.GraphKeys.SAVEABLE_OBJECTS collection for saving and restoring in the manner of a tf.Variable eg:- . saveable = tf.contrib.data.make_saveable_from_iterator(iterator) # save the iterator state by adding it to the saveable objects collection. tf.add_to_collection(tf.GraphKeys.SAVABLE_OBJECTS, saveable) saver = tf.train.Saver() with tf.Session() as sess: if should_checkpoint: saver.save(path_to_checkpoint) # restore the iterator state. with tf.Session() as sess: saver.restore(sess, path_to_checkpoint) . Reading Input Data . Numpy array - if data fits in memory then simplest way is to convert it into tf.Tensor objects and use the Dataset.from_tensor_slices() . with np.load(&quot;path/to/data.npy&quot;) as data : features = data[&#39;features&#39;] labels = data[&#39;labels&#39;] dataset = tf.data.Dataset.from_tensor_slices((features, labels)) . TFRecords Format - TFRecord file format is a simple record-oriented binary format that many TensorFlow applications use for training data. The tf.data.TFRecordDataset class enables us to stream over the contents of one or more TFRecord files as part of an input pipeline. . filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;] dataset = tf.data.TFRecordDataset(filenames) . and this is how we could make use of the tf.placeholder for dynamically working with the TFRecords. . filenames = tf.placeholder(tf.string, shape=[None]) dataset = tf.data.TFRecordDataset(filenames) dataset = dataset.map(...) # Parse the record into tensors. dataset = dataset.repeat() # Repeat the input indefinitely. dataset = dataset.batch(32) iterator = dataset.make_initializable_iterator() # Initialize `iterator` with training data. training_filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;] sess.run(iterator.initializer, feed_dict={filenames: training_filenames}) # Initialize `iterator` with validation data. validation_filenames = [&quot;/var/data/validation1.tfrecord&quot;, ...] sess.run(iterator.initializer, feed_dict={filenames: validation_filenames}) . Working with Text Data . The tf.data.TextLineDataset provides an easy way to extract lines from one or more text files . filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;] dataset = tf.data.TextLineDataset(filenames) . we could also make use of the Dataset.filter(), Dataset.skip functions along with the Dataset.flat_map() for data processing. . filenames = [&quot;/var/data/file1.txt&quot;, &quot;/var/data/file2.txt&quot;] dataset = tf.data.Dataset.from_tensor_slices(filenames) # Use `Dataset.flat_map()` to transform each file as a separate nested dataset, # and then concatenate their contents sequentially into a single &quot;flat&quot; dataset. # * Skip the first line (header row). # * Filter out lines beginning with &quot;#&quot; (comments). dataset = dataset.flat_map( lambda filename: ( tf.data.TextLineDataset(filename) .skip(1) .filter(lambda line: tf.not_equal(tf.substr(line, 0, 1), &quot;#&quot;)))) . Working with CSV Data . tf.contrib.data.CsvDataset() class provides a way to extract records from one or more csv files. the CsvDataset will provide us with tuple of elements. CsvDataset also accepts filenames as a tf.tensor() and hence can be used like other functions described above. . filenames = [&quot;/var/data/file1.csv&quot;, &quot;/var/data/file2.csv&quot;] record_defaults = [tf.float32] * 8 # Eight required float columns dataset = tf.contrib.data.CsvDataset(filenames, record_defaults) . we can also select certain columns, remove certain rows etc in csv as per requirement. . # Creates a dataset that reads all of the records from two CSV files with # headers, extracting float data from columns 2 and 4. record_defaults = [[0.0]] * 2 # Only provide defaults for the selected columns dataset = tf.contrib.data.CsvDataset(filenames, record_defaults, header=True, select_cols=[2,4] . Preprocessing Data with Dataset.map() . The Dataset.map(f) transformation produces a new dataset by applying a given function f to each element of the input dataset. It is based on the map() function that is commonly applied to lists (and other structures) in functional programming languages. lets look into an example. . def _parse_function(example_proto): features = {&quot;image&quot;: tf.FixedLenFeature((), tf.string, default_value=&quot;&quot;), &quot;label&quot;: tf.FixedLenFeature((), tf.int64, default_value=0)} parsed_features = tf.parse_single_example(example_proto, features) return parsed_features[&quot;image&quot;], parsed_features[&quot;label&quot;] filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;] dataset = tf.data.TFRecordDataset(filenames) dataset = dataset.map(_parse_function) . Preprocessing Images with tf.Dataset.map() . below example let us give an understanding on how to work with images in tf.Dataset . # Reads an image from a file, decodes it into a dense tensor, and resizes it # to a fixed shape. def _parse_function(filename, label): image_string = tf.read_file(filename) image_decoded = tf.image.decode_jpeg(image_string) image_resized = tf.image.resize_images(image_decoded, [28, 28]) return image_resized, label # A vector of filenames. filenames = tf.constant([&quot;/var/data/image1.jpg&quot;, &quot;/var/data/image2.jpg&quot;, ...]) # `labels[i]` is the label for the image in `filenames[i]. labels = tf.constant([0, 37, ...]) dataset = tf.data.Dataset.from_tensor_slices((filenames, labels)) dataset = dataset.map(_parse_function) . Applying Python Logic in Map . import cv2 # Use a custom OpenCV function to read the image, instead of the standard # TensorFlow `tf.read_file()` operation. def _read_py_function(filename, label): image_decoded = cv2.imread(filename.decode(), cv2.IMREAD_GRAYSCALE) return image_decoded, label # Use standard TensorFlow operations to resize the image to a fixed shape. def _resize_function(image_decoded, label): image_decoded.set_shape([None, None, None]) image_resized = tf.image.resize_images(image_decoded, [28, 28]) return image_resized, label filenames = [&quot;/var/data/image1.jpg&quot;, &quot;/var/data/image2.jpg&quot;, ...] labels = [0, 37, 29, 1, ...] dataset = tf.data.Dataset.from_tensor_slices((filenames, labels)) dataset = dataset.map( lambda filename, label: tuple(tf.py_func( _read_py_function, [filename, label], [tf.uint8, label.dtype]))) dataset = dataset.map(_resize_function) . Batching Dataset Elements . Simple Batching . The simplest form of batching stacks n consecutive elements of a dataset into a single element. The Dataset.batch() transformation does exactly this, with the same constraints as the tf.stack() operator, applied to each component of the elements: . inc_dataset = tf.data.Dataset.range(100) dec_dataset = tf.data.Dataset.range(0, -100, -1) dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset)) batched_dataset = dataset.batch(4) iterator = batched_dataset.make_one_shot_iterator() next_element = iterator.get_next() print(sess.run(next_element)) # ==&gt; ([0, 1, 2, 3], [ 0, -1, -2, -3]) print(sess.run(next_element)) # ==&gt; ([4, 5, 6, 7], [-4, -5, -6, -7]) print(sess.run(next_element)) # ==&gt; ([8, 9, 10, 11], [-8, -9, -10, -11]) . Batching with padding . sometimes we may need to including padding in our dataset, esp when the dataset we have is not of fixed length. . dataset = tf.data.Dataset.range(100) dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x)) dataset = dataset.padded_batch(4, padded_shapes=[None]) iterator = dataset.make_one_shot_iterator() next_element = iterator.get_next() print(sess.run(next_element)) # ==&gt; [[0, 0, 0], [1, 0, 0], [2, 2, 0], [3, 3, 3]] print(sess.run(next_element)) # ==&gt; [[4, 4, 4, 4, 0, 0, 0], # [5, 5, 5, 5, 5, 0, 0], # [6, 6, 6, 6, 6, 6, 0], # [7, 7, 7, 7, 7, 7, 7]] . Training Workflows . **Processing multiple epochs **- simplest way to iterate over a dataset in multiple epochs is to use the Dataset.repeat() transformation . filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;] dataset = tf.data.TFRecordDataset(filenames) dataset = dataset.map(...) dataset = dataset.repeat(10) dataset = dataset.batch(32) . sometime we want to receive a signal at the end of each epoch, we can write a training loop that catches the tf.errors.OutOfRangeError at the end of dataset . filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;] dataset = tf.data.TFRecordDataset(filenames) dataset = dataset.batch(32) iterator = dataset.make_initializable_iterator() next_element = iterator.get_next() # Compute for 100 epochs. for _ in range(100): sess.run(iterator.initializer) while True: try: sess.run(next_element) except tf.errors.OutOfRangeError: break # [Perform end-of-epoch calculations here.] . Random Shuffling of input data . filenames = [&quot;/var/data/file1.tfrecord&quot;, &quot;/var/data/file2.tfrecord&quot;] dataset = tf.data.TFRecordDataset(filenames) dataset = dataset.shuffle(buffer_size=10000) dataset = dataset.batch(32) dataset = dataset.repeat() .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/11/01/TensorFlow-Learning-(Importing-Data).html",
            "relUrl": "/markdown/2018/11/01/TensorFlow-Learning-(Importing-Data).html",
            "date": " • Nov 1, 2018"
        }
        
    
  
    
        ,"post21": {
            "title": "TensorFlow-2",
            "content": "Tensorflow -7 . So this is a walk through of all the concepts that i have tried to learn in past 2 days about tensorflow. There are 4 highlevel API’s that were introduced in the latest version of TensorFlow (1.9 as on 10-31-2018). lets discuss about each of those 4 high level API’s. . Keras . main features of Keras are User Friendly, Modular and Composable, Easy to extend . Lets dive into code. . import tensorflow as tf from tensorflow import keras . so keras is now being shipped with tensorflow, now there is no need to separately install keras this helps as original keras has multiple backends like theano, tensorflow etc. well now we have keras with just tensorflow and hence lightweight. tf.keras.version could be helpfull incase if you want to know which version of keras are we working with (helpfull when working with prebuild models). . Building a model . the methodolgy is exactly similar to how models were built using keras. . model =keras.Sequential() model.add(keras.layers.Dense(64,activation=&#39;relu&#39;,kernel_regularizer=keras.regularizers.l1(0.01))) model.add(keras.layers.Dense(64,activation=&#39;relu&#39;,bias_initializer=keras.initializers.constant(2.0))) model.add(keras.layers.Dense(10,activation=&#39;softmax&#39;)) . Dense is just one of the layers available in keras.layers there are others like conv2d maxpooling,lstm, etc available and which could be called upon based on the requirements. Similarly for activation also we have multiple functions availble apart from relu and softmax like sigmoid,tanh etc. keras.layers takes in multiple parameters depending upon the type of layer. Some of the important parameters which are common to most layers are number of neurons,kernal_initializerandbias_initializer,kernal_regularizer and bias regularizer. Depending upon the layer there are will be other parameters. . model.compile(optimizer=tf.train.AdamOptimizer(0.001),loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy]&#39;]) . optimizer again has multiple methods like AdamOptimizer,RMSPropOptimzer or GradientDescentOptimizer. loss is the function to minimize during optimization some common methods are categorical_crossentropy ,binary_crossentropy, mse. . metrics is used to monitor how the training is proceeding, gives an idea if our model is improving accuracy, precision, mae etc are some of the important metrics that are used generally. . so we have our model structure ready, lets feed it with data for training. . import numpy as np data = np.random.random((1000, 32)) labels = np.random.random((1000, 10)) val_data = np.random.random((100, 32)) val_labels = np.random.random((100, 10)) model.fit(data, labels, epochs=10, batch_size=32) . model.fit takes three important arguments they are epochs (one iteration over the entire input data) , batch_size (model slices the data into smaller batches and iterates over these batches during training), validation_data (want to easily monitor its performance on some validation data. Passing this argument—a tuple of inputs and labels—allows the model to display the loss and metrics in inference mode for the passed data, at the end of each epoch) . Input Data using tf.data.Dataset . we can pass tf.data.Dataset from Datasets API instead of passing data to the model.fit method. . dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(32) dataset = dataset.repeat() model.fit(dataset, epochs=10, steps_per_epoch=30) . Here the Dataset yeilds batches of data hence batch_size is not required, steps_per_epoch is the number of training steps the model runs before it moves to the next epoch. . Evaluate and Predict . To evaluate and predict we make use of Model.evaluate and Model.predict methods. . model.evaluate(x, y, batch_size=32) # using numpy model.evaluate(dataset, steps=30) #using datasets . model.predict(x, batch_size=32) # using numpy model.predict(dataset, steps=30) #dataset . Functional API for building models . lets try out the functional API method for building a model instead of keras.Sequential() method. . inputs = keras.Input(shape=(32,)) x = keras.layers.Dense(64, activation=&#39;relu&#39;)(inputs) x = keras.layers.Dense(64, activation=&#39;relu&#39;)(x) predictions = keras.layers.Dense(10, activation=&#39;softmax&#39;)(x) model = keras.Model(inputs=inputs, outputs=predictions) model.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(data, labels, batch_size=32, epochs=5) . Now lets go little more deeper, with Model Subclassing. lets build a fully customizable model by subclassing keras. Model with a custom forward pass . Custom Models . class MyModel(keras.Model): def __init__(self, num_classes=10): super(MyModel, self).__init__(name=&#39;my_model&#39;) self.num_classes = num_classes self.dense_1 = keras.layers.Dense(32, activation=&#39;relu&#39;) self.dense_2 = keras.layers.Dense(num_classes, activation=&#39;sigmoid&#39;) def call(self, inputs): x = self.dense_1(inputs) return self.dense_2(x) def compute_output_shape(self, input_shape): shape = tf.TensorShape(input_shape).as_list() shape[-1] = self.num_classes return tf.TensorShape(shape) model = MyModel(num_classes=10) model.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(data, labels, batch_size=32, epochs=5) . Custom Layer . Now let us try to create the same model with a custom layer, a custom layer can be created by subclassing tf.keras.layers.Layers with below methods. build - to create the weights of the layer and .add_weight method helps us to add a weight to layer, call defines the forward pass, compute_output_shape specify how to compute the shape of the output of layer, get_configmethod helps in serializing the data. . class MyLayer(keras.layers.Layer): def __init__(self, output_dim, **kwargs): self.output_dim = output_dim super(MyLayer, self).__init__(**kwargs) def build(self, input_shape): shape = tf.TensorShape((input_shape[1], self.output_dim)) self.kernel = self.add_weight(name=&#39;kernel&#39;, shape=shape, initializer=&#39;uniform&#39;, trainable=True) super(MyLayer, self).build(input_shape) def call(self, inputs): return tf.matmul(inputs, self.kernel) def compute_output_shape(self, input_shape): shape = tf.TensorShape(input_shape).as_list() shape[-1] = self.output_dim return tf.TensorShape(shape) def get_config(self): base_config = super(MyLayer, self).get_config() base_config[&#39;output_dim&#39;] = self.output_dim return base_config @classmethod def from_config(cls, config): return cls(**config) model = keras.Sequential([MyLayer(10), keras.layers.Activation(&#39;softmax&#39;)]) model.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(data, targets, batch_size=32, epochs=5) . Callbacks . A callback is an object passed to a model to customize and extend its behaviour during training some of the widely used callbacks are . tf.keras.callbacks.ModelCheckpoint - to save checkpoint of the model at regular interval. . tf.keras.callbacks.LearningRateScheduler : to change the learning rate . tf.keras.callbacks.EarlyStopping : Interrupt training when validation performance has stopped. . tf.keras.callbacks.TensorBoard : Monitor model’s behavious using tensorboard. . Sample of callbacks . callbacks=[keras.callbacks.EarlyStopping(patience=2, monitor=&#39;val_loss&#39;), keras.callbacks.TensorBoard(log_dir=&#39;./logs&#39;)] model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks, validation_data=(val_data,val_targets)) . Save and Restore a Model . tf.keras.Model.save_weights is used to save a model . model.save_weights(&#39;./my_model&#39;) model.load_weights(&#39;my_model&#39;) . model weights are saved in Tensorflow checkpoint file format. this could be changed to HDF5 format. . model.save_weights(&#39;my_model.h5&#39;, save_format=&#39;h5&#39;) model.load_weights(&#39;my_model.h5&#39;) . Saving the configuration of a model . by serializes the model architecture without any weights. . json_string = model.to_json() # model to json format fresh_model = keras.models.model_from_json(json_string) #create a model with saved json string yaml_string = model.to_yaml() #model to yaml string fresh_model = keras.models.model_from_yaml(yaml_string) #create a model with saved yaml string . Saving and loading an entire model . Entire model can also be saved . . # Create a trivial model model = keras.Sequential([ keras.layers.Dense(10, activation=&#39;softmax&#39;, input_shape=(32,)), keras.layers.Dense(10, activation=&#39;softmax&#39;) ]) model.compile(optimizer=&#39;rmsprop&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.fit(data, targets, batch_size=32, epochs=5) model.save(&#39;my_model.h5&#39;) model = keras.models.load_model(&#39;my_model.h5&#39;) . Eager Execution - tf.keras supports eager execution , eager execution is beneficial for model sub classing and building custom layers . Estimators - tf.estimators are used for training models on distributed environments. A tf.keras.Model can be trained with tf.estimator API by converting the model to an tf.estimator.Estimator object with tf.keras.estimator.model_to_estimator . model = keras.Sequential([layers.Dense(10,activation=&#39;softmax&#39;), layers.Dense(10,activation=&#39;softmax&#39;)]) model.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) estimator = keras.estimator.model_to_estimator(model) . Multiple GPU’s . tf.keras models can run in multiple GPU’s using tf.contrib.distribute.DistributionStrategy we also need to convert the model to estimator object as explained above and then train the estimator. . #create a simple model. model = keras.Sequential() model.add(keras.layers.Dense(16, activation=&#39;relu&#39;, input_shape=(10,))) model.add(keras.layers.Dense(1, activation=&#39;sigmoid&#39;)) optimizer = tf.train.GradientDescentOptimizer(0.2) model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=optimizer) model.summary() # define an input dataset. def input_fn(): x = np.random.random((1024, 10)) y = np.random.randint(2, size=(1024, 1)) x = tf.cast(x, tf.float32) dataset = tf.data.Dataset.from_tensor_slices((x, y)) dataset = dataset.repeat(10) dataset = dataset.batch(32) return dataset # create a distribution strategy and then create a config file. strategy = tf.contrib.distribute.MirroredStrategy() config = tf.estimator.RunConfig(train_distribute=strategy) # create an estimator instance keras_estimator = keras.estimator.model_to_estimator( keras_model=model, config=config, model_dir=&#39;/tmp/model_dir&#39;) # train the estimator keras_estimator.train(input_fn=input_fn, steps=10) . This concludes my first part of tensor flow tutorial. I hope to revisit it soon once i get to learn more aspects on the Estimators or model saving techniques. .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/10/31/TensorFlow-Learning-(tf.keras).html",
            "relUrl": "/markdown/2018/10/31/TensorFlow-Learning-(tf.keras).html",
            "date": " • Oct 31, 2018"
        }
        
    
  
    
        ,"post22": {
            "title": "TensorFlow-1",
            "content": "Tensorflow -8 . So this is a walk through of all the concepts that i have tried to learn in past 2 days about tensorflow. There are 4 highlevel API’s that were introduced in the latest version of TensorFlow (1.9 as on 10-31-2018). lets discuss about second of those 4 high level API’s, first being tf.keras. . Part-2 - Eager Execution . so this is relatively something that tensorflow borrowed from pytorch, in eager execution mode tensorflow just gives away the graphs and sessions paradigm. Here operations are evaluated immediately without building graphs. This makes tensorflow easier to understand as well as debug. The tensorflow code now resembles much more closer to native python code when in Eager execution mode. All the updated tensorflow libraries have the option to enable eager execution. below command quicly enables eager execution. . import tensorflow as tf tf.enable_eager_execution() tf.executing_eagerly() ## returns True in eage_execution mode . so how does this eager execution works. ? simple answer is it works just like python . x = [[2.]] m = tf.matmul(x, x) print(&quot;hello, {}&quot;.format(m)) ## output -&gt; &quot;hello, [[4.]]&quot; . With Numpy . Eager execution works closely with numpy. numpy operations accepts tf.Tensor arguments. tf.Tensor.numpy method returns objects value in numpy. . a = tf.constant([[1, 2],[3, 4]]) print(a) #output =&gt; tf.Tensor([[1 2] [3 4]], shape=(2, 2), dtype=int32) b = tf.add(a, 1) print(b) #output =&gt; tf.Tensor([[2 3] [4 5]], shape=(2, 2), dtype=int32) print(a * b) #output =&gt; tf.Tensor([[ 2 6] [12 20]], shape=(2, 2), dtype=int32) import numpy as np c = np.multiply(a, b) print(c) #output =&gt; [[ 2 6] [12 20]] print(a.numpy()) #output =&gt; [[1 2] [3 4]] . tf.contrib.eager module contains symbols available to both eager and graph execution environments and is useful for writing code to work with graph. Hence we could write If and for loops just like a python variable for a tensorflow variable. . Building a Model . When using tensorflow with eager execution we can write our own layers or use a layer provided in the tf.keras.layers package. tf.keras.layers.Layers can be used as our Base class and inherit from this base class to implement our own custom layer. . class MySimpleLayer(tf.keras.layer.Layer): def __init__(self, output_units): super(MySimpleLayer,self).__init__() self.output_units = output_units def build(self,input_shape): self.kernel = self.add_variable(&quot;kernel&quot;,[input_shape[-1],self.output_units]) def call(self,input): return tf.matmul(input, self.kernel) . So we have a custom layer ready, now we could prepare our model, lets go with the functional way of configuring a model. . class MNISTModel(tf.keras.Model): def __init__(self): super(MNISTModel,self).__init__() self.dense1 = tf.keras.layers.Dense(units=10) self.dense2 = tf.keras.layers.Dense(units=10) def call(self,input): result = self.dense1(input) result = self.dense2(result) result = self.dense2(result) return result model = MNISTModel() . We have a model ready now. lets get to train our model, for that we need to know how to compute the gradient. . Computing Gradient . Automatic differentiation is useful for implementing machine learning algorithms such as backpropagation for training neural networks. During eager execution, use tf.GradientTape to trace operations for computing gradients later. tf.GradientTape is an opt in feature to provide maximal performance when not tracing. To compute gradient we play the tape backwards and then discard. A particular tf.GradientTape can only compute one gradient subsequent calls throws error. . w=tf.Variabel([[1.0]]) with tf.GradientTape() as tape: loss = w*w grad = tape.gradient(loss,w) print(grad) #Output-&gt; tf.Tensor([[2.]] . lets look into this concept and how it is applied in a simple deep learning scenario. . NUM_EXAMPLES=1000 training_inputs=tf.ranndom_normal([NUM_EXAMPLES]) noise=tf.random_normal([NUM_EXAMPLES]) training_outputs = training_inputs*3+2+noise def prediction(input,weight,bias): return input*weight+bias def loss(weights,bias): error = prediction(training_inputs,weights,bias)-training_outputs return tf.reduce_mean(tf.square(error)) def grad(weigths, bias): with tf.GradientTape() as tape: loss_value = loss(weights, biases) return tape.gradient(loss_value,[weights, biases]) train_steps = 200 learning_rate =0.01 W=tf.Variable(5.) W=tf.Variable(10.) print(&quot;Initial Loss : {:.3f}&quot;.format(loss(W,B))) for i in range(train_steps): dW, dB = grad(W,B) W.assign_sub(dW*learning_rate) W.assign_sub(dB*learning_rate) if i%20==0: print(&quot;Loss at Step {:03d}:{:.3f}&quot;.format(i, loss(W,B))) print(&quot;Final loss: {:.3f}&quot;.format(loss(W,B))) print(&quot;W={},B={}&quot;.format(W.numpy(),B.numpy())) . This should be able to help you understand how to write a simple regression model in tensorflow. now lets look into writing a simple classification problem using vanila tensorflow. . Classification - MNIST Digit dataset . import dataset dataset_train = dataset.train(&#39;./datasets&#39;).shuffle(60000).repeat(4).batch(32) def loss(model, x, y): prediction = model(x) return tf.losses.sparse_softmax_crossentropy(labels=y, logits=prediction) def grad(model, inputs, targets): with tf.GradientTape() as tape: loss_value = loss(model,inputs,targets) return tape.gradient(loss_Value, model.variables) optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001) x,y = iter(dataset_train).next() print(&quot;Initial loss: {:.3f}&quot;.format(loss(model, x, y))) for (i ,(x,y)) in enumerate(dataset_train): grads=grad(model, x, y) optimizer.apply_gradients(zip(grads,model.variables), global_step = tf.train.get_or_create_global_step()) if i%200==0: print(&quot;Loss at step {:.4d}:{:.3f}&quot;.format(i, loss(model, x, y))) print(&quot;Final loss : {:.3f}&quot;.format(loss(model, x, y))) . we could also move the computation to GPU for faster training. . with tf.device(&quot;/gpu:0&quot;): for (i ,(x,y)) in enumerate(dataset_train): optimizer.minimize(lambda:loss(model, x, y), global_step = tf.train.get_or_create_global_step()) . Variables and Optimizers . tf.Variable object stores mutable tf.Tensor values accessed during training to make automatic differentiation easier. The parameters of a model can be encapsulated in classes as tf.Variables with tf.GradientTape. lets try this out. . class Model(tf.keras.Model): def __init__(self): super(Model, self).__init__() self.W = tf.Variable(5., name=&#39;weight&#39;) self.B = tf.Variable(10., name=&#39;bias&#39;) def call (self, inputs): return inputs*self.W +self.B NUM_EXAMPLES = 2000 training_inputs = tf.random_normal([NUM_EXAMPLES]) noise = tf.random_normal([NUM_EXAMPLES]) training_outputs = training_inputs*3 + 2 + noise def loss(model, inputs, targets): error = model(inputs) - targets return tf.reduce_mean(tf.square(error)) def grad(model, inputs, targets): with tf.GradientTape() as tape: loss_value = loss(model, inputs, targets) return tape.gradient(loss_value, [model.W, model.B]) model = Model() optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01) print(&quot;Initial loss : {:.3f}&quot;.format(loss(model, training_inputs, training_outputs))) for i in range(300): grads = grad(model, training_inputs, training_outputs) optimizer.apply_gradients(zip(grads, [Model.W, model.B]),global_step=tf.train.get_or_create_global_step()) if i % 20==0: print(&quot;Loss at step {:03d}: {:.3f}&quot;.format(i,loss(model, training_inputs, training_outputs))) print(&quot;Final Loss : {:.3f}&quot;.format(loss(model, training_inputs, training_outputs))) print(&quot;W = {}, B = {}&quot;.format(model.W.numpy(),model.B.numpy())) . Object Based Saving . tf.train.Checkpoint can save and restore tf.Variable to and fro from checkpoints. . x = tf.Variable(10.) checkpoint = tf.train.Checkpoint(x=x) x.assign(2.) save_path = checkpoint.save(&#39;./ckpt/&#39;) x.assign(11.) checkpoint.restore(save_path) print(x) #output -&gt; 2.0 . To save and load Model through Checkpoints . to record the state of a model an optimizer and a global step we need to pass them to a tf.train.Checkpoint stores the internal state of objects, without requiring hidden variables. lets try this out. . model = MyModel() optimizer = tf.train.AdamOptimizer(learning_rate=.001) checkpoint_dir = &#39;/path_to_model_dir&#39; checkpoint_prefix = os.path.join(checkpoint_dir,&quot;ckpt&quot;) root = tf.train.Checkpoint(optimizer, model = model, optimizer_step = tf.train.get_or_create_global_step()) root.save(file_prefix = checkpoint_prefix) #or root.restore(tf.train.latest_checkpoint(checkpoint_dir)) . Object Oriented Metrics . we could store metrics as a variable as shown below. . m = tfe.metrics.Mean(&quot;loss&quot;) m(0) m(5) m.result() # output -&gt; 2.5 m([8,9]) m.result() # output -&gt; 5.5 . Summaries and TensorBoard . TensorBoard is a visualisation tool for understanding, debugging and optimising the model training process. it uses summary events to display it to the user. . tf.contrib.summary is compatible with both wager and graph execution environments. Summary operations such as tf.contrib.summary.scalar are inserted during model construction . lets see how to do this. . global_step = tf.train.get_or_create_global_step() writer = tf.contrib.summary.create_file_writer(logdir) writer.set_as_default() for _ in range(iterations): global_step.assign_add(1) with tf.contrib.summary.record_summaries_every_n_global_steps(100): tf.contrib.summary.scalar(&#39;loss&#39;,loss) .... . Automatic Differentiation : Advanced Concepts . Dynamic Model - tf.GradientTape can also be used with dynamic model. . def line_search_step(fn, init_x, rate =1.0): tape.watch(init_x) value = fn(init_x) grad = tape.gradient(value, init_x) grad_norm = tf.reduce_sum(grad*grad) init_value = value while value &gt; init_value -rate*grad_norm x = init_x - rate*grad value = fb(x) rate /=2.0 return x, value . Like tf.GradientTape there are other major functions to compute gradients some of them are discussed below. These functions are usefull for writing math code with only tensor and gradient functions and without tf.Variables . tfe.gradients_function - Returns a function that computes the derivatives of its input function parameter with respect to its arguments. . tfe.value_and_gradients_function - simialar to tfe.gradients_function it returns the value from the input function in addition to the list of derivatives of the input function with respect to its arguments. . lets work on some examples . def square(x): return tf.multiply(x,x) grad = tfe.gradients_function(square) square(3.) # output -&gt; 9.0 grad(3.) # output -&gt; [6.0] gradgrad = tf.gradients_function(lambda x:grad(x)[0]) grad(3.) #output -&gt; [2.0] gradgradgrad = tfe.gradients_function(lambda x: gradgrad(x)[0]) gradgradgrad(3.) #output -&gt; [None] def abs(x): return x if x &gt; 0. else -x grad = tfe.gradients_function(abs) grad(3.) #output -&gt; [1.0] grad(-3.) #output -&gt; [-1.0] . Custom Gradient . lets consider below example . . def log1pexp(x): return tf.log(1+tf.exp(x)) grad+log1pexp = tfe.gradients_function(log1pexp) grad_log1pexp(0) #output -&gt; [0.5] grad_log1pexp(100) #output -&gt; [nan] # x=100 fails because of numerical instability. . Now let us create a custom gradient for above function . @tf.custom_gradient def log1pexp(x): e = tf.exp(x) def grad(dy): return dy * (1-1 / (1+e)) return tf.log(1+e), grad grad_log1pexp = tfe.gradients_function(log1pexp) #As before, the gradient computation works fine at x=0 grad_log1pexp(0.) #output -&gt; [0.5] # and the gradient computation also works at x=100 grad_log1pexp(100.) #output-&gt; [1.0] . Performance . In eager execution computation is automatically offloaded to GPU. however this could be controlled using tf.device(&#39;/gpu:0&#39;) or tf.device(&#39;cpu:0&#39;) command as per necessity. lets try this . import time def measure (x, steps): tf.matmul(x,x) start = time.time() for i in range(steps): x = tf.matmul(x,x) _ = x.numpy() end = time.time() return end - start shape = (1000, 1000) steps = 200 print(&quot;Time to multiply a {} matric by itself {} times :&quot;.format(shape, steps)) # run on CPU: with tf.device(&quot;/cpu:0&quot;): print(&quot;CPU:{} secs&quot;.format(measure(tf.random_normal(shape),steps))) # run on GPU, if available: if tfe.num_gpus()&gt;0: with tf.device(&quot;/gpu:0&quot;): print(&quot;GPU:{} secs&quot;.format(measure(tf.random_normal(shape),steps))) else: print(&quot;GPU: not found&quot;) . Lets also try to compute some operation in GPU while part in CPU. . x = tf.random_normal([10,10]) x_gpu0 = x.gpu() x_cpu = x.cpu() _ = tf.matmul(x_cpu,x_cpu) _ = tf.matmul(x_gpu0,x_gpu0) if tfe.num_gpus() &gt; 1: x_gpu1=x.gpu(1) _ = tf.matmul(x_gpu1,x_gpu1) . Working with Graphs . eager execution makes development and debugging more interactive. But TensorFlow graph execution does have some advantages like distributed training, performance optimisations and production deployment. But writing a graph code is different from python code and it is quite difficult to decode for a student programmer. an eager execution code will also run in tensorflow graph execution, the only difference would be that that we wont have to use tf.enable_eager_execution() in the beginning of our session. As per the tensorflow guide the best way to write a tensorflow program is to write the code parallely in eager execution mode and graph mode. test and debug in eager execution mode while run and deploy in graph mode. . Using eager execution in Graph mode . below example selectively enable eager execution in a tensorflow graph environment using tfe.py_func interesting thing here is we have not used tf.enable_eager_execution() at all. . def my_py_func(x): x = tf.matmul(x,x) print(x) return x with tf.Session() as sess: x = tf.placeholder (dtype = tf.float32) # call eager function in graph! pf = tfe.py_func(my_py_func,[x], tf.float32) sess.run(pf, feed_dict = {x :[[2.0]]}) #output -&gt; [[4.0]] .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/10/31/TensorFlow-Learning-(tf-EagerExecution).html",
            "relUrl": "/markdown/2018/10/31/TensorFlow-Learning-(tf-EagerExecution).html",
            "date": " • Oct 31, 2018"
        }
        
    
  
    
        ,"post23": {
            "title": "pydata james powell",
            "content": "Python Expert . This is a summary of the talk of James Powell for PyData Seattle conference (24-Jun-2017). Here is the youtube video of the event, https://www.youtube.com/watch?v=cKPlPJyQrt4&amp;t=2146s . He talks about data model concepts in python,like . __init__ method, __repr__, __add__ etc .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/10/29/pyData-James-Powell-So-you-want-to-be-a-python-expert.html",
            "relUrl": "/markdown/2018/10/29/pyData-James-Powell-So-you-want-to-be-a-python-expert.html",
            "date": " • Oct 29, 2018"
        }
        
    
  
    
        ,"post24": {
            "title": "Recommender System",
            "content": "Recommender System . Why we need recommender system ? . ​ Web applications would love to give curated content to the user so that he has a good quality of options visible to him/her while using the web application. . eg:- . Scenario 1 -Customized News articles - a news agency website would want to give customized news to each of its user based on the reading habits of each user. . Scenario 2 - Based on past history data what a customer would like to buy . Types of Recommender Systems . Content based systems - examine properties of the items recommended . Collaborative filtering systems - recommend items based on similarity measures between users and/or items. . Utility Matrix . ​ In a recommender system, we are usualy trying to identify potential relationship between two classes namely User and item. The Data showing the relationship between these two classes (User -row and Item in col) is called a Utility Matrix. Utility matrix are generally Sparse Matrix (Matrix which has a value only when a relationship exist between both entities, hence most elements are zero in a sparse matrix . ​ Eventhough the goal of a recommender system is to predict the blanks in the utility matrix, it is not necessary to predict every blank, it is necessary only to predict certain items that have a very high probablity. . Long Tail (Marketing Theory) . ​ Physical delivery systems are characterized by a scarcity of resources. Brick-and-mortar stores have limited shelf space, and can show the customer only a small fraction of all the choices that exist. Hence in real world stores it is not possible to tailor each store based on the choice of each individual customer. However this is not the case with an online store, they have virtually infinite store space. And hence an online store showcase rare products that are not necessarily provided in custom physical store (because of less demand / more shelf space). But this long tail phenomenon leaves an online user with another problem the screen space in a laptop / mobile with which a user surfs the website is limited hence the retailer should be meticulous that he is providing items that intrests the user and guess who helps a retailer to solve this problem, yep Recommender systems to your help. ! . Content Based Recommendations . This approach as mentioned previously focus on the properties of the item hence an Item Profile becomes necessary. eg:- Movie Genre is an important item in the Item profile of a movie. If the data that we are working is a document or an image the process becomes tricky. like movie genre for movies we need to have a topic for a document, so that we can recommend document based on topics. . Topic detection using TFIDF will become handy here. we first remove the stop words from the document and then compute the TFIDF score of each word in the document and the onces with highest frequency characterizes the document. . Now if the data is images how do we get the profile of an image ? Tagging Of Images comes into picture here. This is still a research area perhaps i would comeback later to explore on the methods of tagging images. . So the important aspect of a content based recommendation is the generation of profile vectors for both user and item there be we can match items to users as well as users to item both ways depending the need. Once the profile vectors are created, we could easily find out the similarity based on distance metrics like cosine distance. . Collaborative Filtering . In collaborative filtering we focus on the similarity of one user vector (each single row in the sparse matrix). if the user vectors are close according to some distance criteria we assume that users are similar. Recommendation for a user is made by looking at the user that are more similar to U in this sense. The process of identifying similar user and then recommending what similar users like is called collaborative filtering. . Reference :- .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/10/28/pyData-Stephan-Elston-Data-Visualization-and-Exploration-Summary.html",
            "relUrl": "/markdown/2018/10/28/pyData-Stephan-Elston-Data-Visualization-and-Exploration-Summary.html",
            "date": " • Oct 28, 2018"
        }
        
    
  
    
        ,"post25": {
            "title": "Recommender System -2",
            "content": "Recommender System . Why we need recommender system ? . ​ Web applications would love to give curated content to the user so that he has a good quality of options visible to him/her while using the web application. . eg:- . Scenario 1 -Customized News articles - a news agency website would want to give customized news to each of its user based on the reading habits of each user. . Scenario 2 - Based on past history data what a customer would like to buy . Types of Recommender Systems . Content based systems - examine properties of the items recommended . Collaborative filtering systems - recommend items based on similarity measures between users and/or items. . Utility Matrix . ​ In a recommender system, we are usualy trying to identify potential relationship between two classes namely User and item. The Data showing the relationship between these two classes (User -row and Item in col) is called a Utility Matrix. Utility matrix are generally Sparse Matrix (Matrix which has a value only when a relationship exist between both entities, hence most elements are zero in a sparse matrix . ​ Eventhough the goal of a recommender system is to predict the blanks in the utility matrix, it is not necessary to predict every blank, it is necessary only to predict certain items that have a very high probablity. . Long Tail (Marketing Theory) . ​ Physical delivery systems are characterized by a scarcity of resources. Brick-and-mortar stores have limited shelf space, and can show the customer only a small fraction of all the choices that exist. Hence in real world stores it is not possible to tailor each store based on the choice of each individual customer. However this is not the case with an online store, they have virtually infinite store space. And hence an online store showcase rare products that are not necessarily provided in custom physical store (because of less demand / more shelf space). But this long tail phenomenon leaves an online user with another problem the screen space in a laptop / mobile with which a user surfs the website is limited hence the retailer should be meticulous that he is providing items that intrests the user and guess who helps a retailer to solve this problem, yep Recommender systems to your help. ! . Content Based Recommendations . This approach as mentioned previously focus on the properties of the item hence an Item Profile becomes necessary. eg:- Movie Genre is an important item in the Item profile of a movie. If the data that we are working is a document or an image the process becomes tricky. like movie genre for movies we need to have a topic for a document, so that we can recommend document based on topics. . Topic detection using TFIDF will become handy here. we first remove the stop words from the document and then compute the TFIDF score of each word in the document and the onces with highest frequency characterizes the document. . Now if the data is images how do we get the profile of an image ? Tagging Of Images comes into picture here. This is still a research area perhaps i would comeback later to explore on the methods of tagging images. . So the important aspect of a content based recommendation is the generation of profile vectors for both user and item there be we can match items to users as well as users to item both ways depending the need. Once the profile vectors are created, we could easily find out the similarity based on distance metrics like cosine distance. . Collaborative Filtering . In collaborative filtering we focus on the similarity of one user vector (each single row in the sparse matrix). if the user vectors are close according to some distance criteria we assume that users are similar. Recommendation for a user is made by looking at the user that are more similar to U in this sense. The process of identifying similar user and then recommending what similar users like is called collaborative filtering. . Reference :- .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/10/24/Literature-Review-Recommender-System.html",
            "relUrl": "/markdown/2018/10/24/Literature-Review-Recommender-System.html",
            "date": " • Oct 24, 2018"
        }
        
    
  
    
        ,"post26": {
            "title": "TimeSeries - Random Walk",
            "content": "Time Series - Random Walk . ​ So a simple google search on above topic gave quite a lot of results, along with some research papers and links to custom libraries. I was trying to understand the varies methodologies that currently exist to generate dummy data based on a say a very small number of samples. This could be very mush relatable for quite a lot of data scientist. It is a very common occurance that your stake holder might just say “This is all the data i have, now show us what you could come with this”. Well my study here is to come up with an effective solution for all the data scientist who are challenged by their stake holders. . Random Walk (A better approach than Random Generation) . ​ So the first thing that crossed my mind was create a list of values and then use random function and pick random values from the list to extrapolate the data. Well this could work, but that would be naive imagine the situation where we would love the generated data to follow the same trend of the sample data. Random Walk is one such method that could come to our help. . What is random walk? . ​ So my Primary understanding about Random Walk was that we are choosing a random number from a given random set / range of values. But I was clearly wrong.!! . Jason Brownlee’s Blog on Random Walk corrected my basic understanding of the concept of Random Walk in Time Series domain. The most important factor one needs to have about random walk is that “the next value in the sequence is a modification of the previous value in the sequence.” Or n my words the next time step is not random it is dependent on previous value . This could be mathematicaly explained as y(t) = B0 + B1*X(t-1) + e(t) where y(t) is the next value in the series, B0 is the constant drift / trend to be associate with y(t), B1 is the weight of effect of previous time step (this is value is generally between -1 &amp; 1) , e(t) is the stochastic error to be induced the time series. So, We have a perfect Equation into which we need to feed the input values to get a Random Walk effect. Now let us check out how to implement this in python. . from random import seed import random from matplotlib import pyplot seed(120) B0=0.002 random_walk = list() random_walk.append(B0-1 if random.random() &lt; 0.5 else B0+1) for i in range(1, 1000): movement = -1 if random.random() &lt; 0.5 else 1 value = B0+random_walk[i-1] + movement+random.randint(-100,100)*.001 random_walk.append(value) pyplot.plot(random_walk) pyplot.show() . . So this looks a time series data, and generated randomly using random walk methodology. This could be used to comeup with a random dataset which would actualy resembles a realworld random process (like stock market). . Reference : Jason Brownlee’s Blog on Random Walk .",
            "url": "https://datapsyche.github.io/fastpages/markdown/2018/10/22/Time-Series-Data-Generation-Random-Walk.html",
            "relUrl": "/markdown/2018/10/22/Time-Series-Data-Generation-Random-Walk.html",
            "date": " • Oct 22, 2018"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://datapsyche.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

}