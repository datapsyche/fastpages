<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://datapsyche.github.io/fastpages/feed.xml" rel="self" type="application/atom+xml" /><link href="https://datapsyche.github.io/fastpages/" rel="alternate" type="text/html" /><updated>2020-04-11T09:42:15-05:00</updated><id>https://datapsyche.github.io/fastpages/feed.xml</id><title type="html">False Positive</title><subtitle>Blog to track progress in data science.</subtitle><entry><title type="html">My First Post in FastPages Blog</title><link href="https://datapsyche.github.io/fastpages/jupyter/2020/04/10/jithin_test.html" rel="alternate" type="text/html" title="My First Post in FastPages Blog" /><published>2020-04-10T00:00:00-05:00</published><updated>2020-04-10T00:00:00-05:00</updated><id>https://datapsyche.github.io/fastpages/jupyter/2020/04/10/jithin_test</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/jupyter/2020/04/10/jithin_test.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/11-04-20-jithin_test.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;About&quot;&gt;About&lt;a class=&quot;anchor-link&quot; href=&quot;#About&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;So I'm just checking out the new fastpages blogging platform and this is my first post on this platform&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Fastpages Notebook Blog Post</title><link href="https://datapsyche.github.io/fastpages/jupyter/2020/02/20/test.html" rel="alternate" type="text/html" title="Fastpages Notebook Blog Post" /><published>2020-02-20T00:00:00-06:00</published><updated>2020-02-20T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/jupyter/2020/02/20/test</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/jupyter/2020/02/20/test.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-02-20-test.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;About&quot;&gt;About&lt;a class=&quot;anchor-link&quot; href=&quot;#About&quot;&gt; &lt;/a&gt;&lt;/h1&gt;&lt;p&gt;This notebook is a demonstration of some of capabilities of &lt;a href=&quot;https://github.com/fastai/fastpages&quot;&gt;fastpages&lt;/a&gt; with notebooks.&lt;/p&gt;
&lt;p&gt;With &lt;code&gt;fastpages&lt;/code&gt; you can save your jupyter notebooks into the &lt;code&gt;_notebooks&lt;/code&gt; folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts!&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Front-Matter&quot;&gt;Front Matter&lt;a class=&quot;anchor-link&quot; href=&quot;#Front-Matter&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Title
&amp;gt; Awesome summary

- toc:true- branch: master- badges: true- comments: true
- author: Hamel Husain &amp;amp; Jeremy Howard
- categories: [fastpages, jupyter]&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Setting &lt;code&gt;toc: true&lt;/code&gt; will automatically generate a table of contents&lt;/li&gt;
&lt;li&gt;Setting &lt;code&gt;badges: true&lt;/code&gt; will automatically include GitHub and Google Colab links to your notebook.&lt;/li&gt;
&lt;li&gt;Setting &lt;code&gt;comments: true&lt;/code&gt; will enable commenting on your blog post, powered by &lt;a href=&quot;https://github.com/utterance/utterances&quot;&gt;utterances&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More details and options for front matter can be viewed on the &lt;a href=&quot;https://github.com/fastai/fastpages#front-matter-related-options&quot;&gt;front matter section&lt;/a&gt; of the README.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Markdown-Shortcuts&quot;&gt;Markdown Shortcuts&lt;a class=&quot;anchor-link&quot; href=&quot;#Markdown-Shortcuts&quot;&gt; &lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;A &lt;code&gt;#hide&lt;/code&gt; comment at the top of any code cell will hide &lt;strong&gt;both the input and output&lt;/strong&gt; of that cell in your blog post.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;#hide_input&lt;/code&gt; comment at the top of any code cell will &lt;strong&gt;only hide the input&lt;/strong&gt; of that cell.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;

&lt;div class=&quot;output_subarea output_stream output_stdout output_text&quot;&gt;
&lt;pre&gt;The comment #hide_input was used to hide the code that produced this.
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;put a &lt;code&gt;#collapse-hide&lt;/code&gt; flag at the top of any cell if you want to &lt;strong&gt;hide&lt;/strong&gt; that cell by default, but give the reader the option to show it:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-hide&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;altair&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;alt&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;put a &lt;code&gt;#collapse-show&lt;/code&gt; flag at the top of any cell if you want to &lt;strong&gt;show&lt;/strong&gt; that cell by default, but give the reader the option to hide it:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;details class=&quot;description&quot; open=&quot;&quot;&gt;
      &lt;summary class=&quot;btn btn-sm&quot; data-open=&quot;Hide Code&quot; data-close=&quot;Show Code&quot;&gt;&lt;/summary&gt;
        &lt;p&gt;&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;#collapse-show&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/cars.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/movies.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sp500&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/sp500.csv&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/stocks.csv&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/flights-5k.json&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/p&gt;
    &lt;/details&gt;
&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Interactive-Charts-With-Altair&quot;&gt;Interactive Charts With Altair&lt;a class=&quot;anchor-link&quot; href=&quot;#Interactive-Charts-With-Altair&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Charts made with Altair remain interactive.  Example charts taken from &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum&quot;&gt;this repo&lt;/a&gt;, specifically &lt;a href=&quot;https://github.com/uwdata/visualization-curriculum/blob/master/altair_interaction.ipynb&quot;&gt;this notebook&lt;/a&gt;.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-1:-DropDown&quot;&gt;Example 1: DropDown&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-1:-DropDown&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# single-value selection over [Major_Genre, MPAA_Rating] pairs&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# use specific hard-wired values as the initial selected values&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Select&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Drama&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;R&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Major_Genre&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binding_select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;genres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binding_radio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mpaa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
&lt;span class=&quot;c1&quot;&gt;# scatter plot, modify opacity based on selection&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-1a49e83878ce4d678d7b162f3d6b510f&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-1a49e83878ce4d678d7b162f3d6b510f&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/movies.json&quot;}, &quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;opacity&quot;: {&quot;condition&quot;: {&quot;value&quot;: 0.75, &quot;selection&quot;: &quot;Select&quot;}, &quot;value&quot;: 0.05}, &quot;tooltip&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Title&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;IMDB_Rating&quot;}}, &quot;selection&quot;: {&quot;Select&quot;: {&quot;type&quot;: &quot;single&quot;, &quot;fields&quot;: [&quot;Major_Genre&quot;, &quot;MPAA_Rating&quot;], &quot;init&quot;: {&quot;Major_Genre&quot;: &quot;Drama&quot;, &quot;MPAA_Rating&quot;: &quot;R&quot;}, &quot;bind&quot;: {&quot;Major_Genre&quot;: {&quot;input&quot;: &quot;select&quot;, &quot;options&quot;: [&quot;Action&quot;, &quot;Adventure&quot;, &quot;Black Comedy&quot;, &quot;Comedy&quot;, &quot;Concert/Performance&quot;, &quot;Documentary&quot;, &quot;Drama&quot;, &quot;Horror&quot;, &quot;Musical&quot;, &quot;Romantic Comedy&quot;, &quot;Thriller/Suspense&quot;, &quot;Western&quot;]}, &quot;MPAA_Rating&quot;: {&quot;input&quot;: &quot;radio&quot;, &quot;options&quot;: [&quot;G&quot;, &quot;PG&quot;, &quot;PG-13&quot;, &quot;R&quot;, &quot;NC-17&quot;, &quot;Not Rated&quot;]}}}}, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-2:-Tooltips&quot;&gt;Example 2: Tooltips&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-2:-Tooltips&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_interval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;scales&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encodings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minExtent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# use min extent to stabilize axis title placement&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tooltip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Release_Date:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-c022b476f4fb482ca6f609bf6ed082d2&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-c022b476f4fb482ca6f609bf6ed082d2&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/movies.json&quot;}, &quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;tooltip&quot;: [{&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Title&quot;}, {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;Release_Date&quot;}, {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;IMDB_Rating&quot;}, {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}], &quot;x&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;Rotten_Tomatoes_Rating&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;axis&quot;: {&quot;minExtent&quot;: 30}, &quot;field&quot;: &quot;IMDB_Rating&quot;}}, &quot;height&quot;: 400, &quot;selection&quot;: {&quot;selector001&quot;: {&quot;type&quot;: &quot;interval&quot;, &quot;bind&quot;: &quot;scales&quot;, &quot;encodings&quot;: [&quot;x&quot;]}}, &quot;width&quot;: 600, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Example-3:-More-Tooltips&quot;&gt;Example 3: More Tooltips&lt;a class=&quot;anchor-link&quot; href=&quot;#Example-3:-More-Tooltips&quot;&gt; &lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# select a point for which to provide details-on-demand&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;selection_single&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;encodings&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;x&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# limit selection to x-axis value&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;mouseover&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# select on mouseover events&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nearest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# select data point nearest the cursor&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;none&amp;#39;&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# empty selection includes no data points&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define our base line chart of stock prices&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date:T&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;log&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;symbol:N&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# base line chart&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# add a rule mark to serve as a guide line&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Chart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_rule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;#aaa&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date:T&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# add circle marks for selected time points, hide unselected points&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_circle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;opacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_selection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# add white stroked text to provide a legible background for labels&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;align&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stroke&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;white&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strokeWidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# add text labels for stock prices&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mark_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;align&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;left&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;price:Q&amp;#39;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stocks&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;properties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;

&lt;div id=&quot;altair-viz-9283d3681fd24aafa3d1e2f9ad193ecf&quot;&gt;&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
  (function(spec, embedOpt){
    const outputDiv = document.getElementById(&quot;altair-viz-9283d3681fd24aafa3d1e2f9ad193ecf&quot;);
    const paths = {
      &quot;vega&quot;: &quot;https://cdn.jsdelivr.net/npm//vega@5?noext&quot;,
      &quot;vega-lib&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lib?noext&quot;,
      &quot;vega-lite&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext&quot;,
      &quot;vega-embed&quot;: &quot;https://cdn.jsdelivr.net/npm//vega-embed@6?noext&quot;,
    };

    function loadScript(lib) {
      return new Promise(function(resolve, reject) {
        var s = document.createElement('script');
        s.src = paths[lib];
        s.async = true;
        s.onload = () =&gt; resolve(paths[lib]);
        s.onerror = () =&gt; reject(`Error loading script: ${paths[lib]}`);
        document.getElementsByTagName(&quot;head&quot;)[0].appendChild(s);
      });
    }

    function showError(err) {
      outputDiv.innerHTML = `&lt;div class=&quot;error&quot; style=&quot;color:red;&quot;&gt;${err}&lt;/div&gt;`;
      throw err;
    }

    function displayChart(vegaEmbed) {
      vegaEmbed(outputDiv, spec, embedOpt)
        .catch(err =&gt; showError(`Javascript Error: ${err.message}&lt;br&gt;This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));
    }

    if(typeof define === &quot;function&quot; &amp;&amp; define.amd) {
      requirejs.config({paths});
      require([&quot;vega-embed&quot;], displayChart, err =&gt; showError(`Error loading script: ${err.message}`));
    } else if (typeof vegaEmbed === &quot;function&quot;) {
      displayChart(vegaEmbed);
    } else {
      loadScript(&quot;vega&quot;)
        .then(() =&gt; loadScript(&quot;vega-lite&quot;))
        .then(() =&gt; loadScript(&quot;vega-embed&quot;))
        .catch(showError)
        .then(() =&gt; displayChart(vegaEmbed));
    }
  })({&quot;config&quot;: {&quot;view&quot;: {&quot;continuousWidth&quot;: 400, &quot;continuousHeight&quot;: 300}}, &quot;layer&quot;: [{&quot;mark&quot;: &quot;line&quot;, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}}, {&quot;mark&quot;: {&quot;type&quot;: &quot;rule&quot;, &quot;color&quot;: &quot;#aaa&quot;}, &quot;encoding&quot;: {&quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}, {&quot;mark&quot;: &quot;circle&quot;, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;opacity&quot;: {&quot;condition&quot;: {&quot;value&quot;: 1, &quot;selection&quot;: &quot;selector002&quot;}, &quot;value&quot;: 0}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;selection&quot;: {&quot;selector002&quot;: {&quot;type&quot;: &quot;single&quot;, &quot;encodings&quot;: [&quot;x&quot;], &quot;on&quot;: &quot;mouseover&quot;, &quot;nearest&quot;: true, &quot;empty&quot;: &quot;none&quot;}}}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;left&quot;, &quot;dx&quot;: 5, &quot;dy&quot;: -5, &quot;stroke&quot;: &quot;white&quot;, &quot;strokeWidth&quot;: 2}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;text&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}, {&quot;mark&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;align&quot;: &quot;left&quot;, &quot;dx&quot;: 5, &quot;dy&quot;: -5}, &quot;encoding&quot;: {&quot;color&quot;: {&quot;type&quot;: &quot;nominal&quot;, &quot;field&quot;: &quot;symbol&quot;}, &quot;text&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;}, &quot;x&quot;: {&quot;type&quot;: &quot;temporal&quot;, &quot;field&quot;: &quot;date&quot;}, &quot;y&quot;: {&quot;type&quot;: &quot;quantitative&quot;, &quot;field&quot;: &quot;price&quot;, &quot;scale&quot;: {&quot;type&quot;: &quot;log&quot;}}}, &quot;transform&quot;: [{&quot;filter&quot;: {&quot;selection&quot;: &quot;selector002&quot;}}]}], &quot;data&quot;: {&quot;url&quot;: &quot;https://vega.github.io/vega-datasets/data/stocks.csv&quot;}, &quot;height&quot;: 400, &quot;width&quot;: 700, &quot;$schema&quot;: &quot;https://vega.github.io/schema/vega-lite/v4.0.2.json&quot;}, {&quot;mode&quot;: &quot;vega-lite&quot;});
&lt;/script&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Data-Tables&quot;&gt;Data Tables&lt;a class=&quot;anchor-link&quot; href=&quot;#Data-Tables&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You can display tables per the usual way in your blog:&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;
&lt;div class=&quot;input&quot;&gt;

&lt;div class=&quot;inner_cell&quot;&gt;
    &lt;div class=&quot;input_area&quot;&gt;
&lt;div class=&quot; highlight hl-ipython3&quot;&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;https://vega.github.io/vega-datasets/data/movies.json&amp;#39;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;movies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# display table with pandas&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Title&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Worldwide_Gross&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;s1&quot;&gt;&amp;#39;Production_Budget&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Distributor&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;MPAA_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;IMDB_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;Rotten_Tomatoes_Rating&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;output_wrapper&quot;&gt;
&lt;div class=&quot;output&quot;&gt;

&lt;div class=&quot;output_area&quot;&gt;


&lt;div class=&quot;output_html rendered_html output_subarea output_execute_result&quot;&gt;
&lt;div&gt;
&lt;style scoped=&quot;&quot;&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&quot;1&quot; class=&quot;dataframe&quot;&gt;
  &lt;thead&gt;
    &lt;tr style=&quot;text-align: right;&quot;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Title&lt;/th&gt;
      &lt;th&gt;Worldwide_Gross&lt;/th&gt;
      &lt;th&gt;Production_Budget&lt;/th&gt;
      &lt;th&gt;Distributor&lt;/th&gt;
      &lt;th&gt;MPAA_Rating&lt;/th&gt;
      &lt;th&gt;IMDB_Rating&lt;/th&gt;
      &lt;th&gt;Rotten_Tomatoes_Rating&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;The Land Girls&lt;/td&gt;
      &lt;td&gt;146083.0&lt;/td&gt;
      &lt;td&gt;8000000.0&lt;/td&gt;
      &lt;td&gt;Gramercy&lt;/td&gt;
      &lt;td&gt;R&lt;/td&gt;
      &lt;td&gt;6.1&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;First Love, Last Rites&lt;/td&gt;
      &lt;td&gt;10876.0&lt;/td&gt;
      &lt;td&gt;300000.0&lt;/td&gt;
      &lt;td&gt;Strand&lt;/td&gt;
      &lt;td&gt;R&lt;/td&gt;
      &lt;td&gt;6.9&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;I Married a Strange Person&lt;/td&gt;
      &lt;td&gt;203134.0&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;Lionsgate&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;6.8&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Let's Talk About Sex&lt;/td&gt;
      &lt;td&gt;373615.0&lt;/td&gt;
      &lt;td&gt;300000.0&lt;/td&gt;
      &lt;td&gt;Fine Line&lt;/td&gt;
      &lt;td&gt;None&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;13.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Slam&lt;/td&gt;
      &lt;td&gt;1087521.0&lt;/td&gt;
      &lt;td&gt;1000000.0&lt;/td&gt;
      &lt;td&gt;Trimark&lt;/td&gt;
      &lt;td&gt;R&lt;/td&gt;
      &lt;td&gt;3.4&lt;/td&gt;
      &lt;td&gt;62.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Images&quot;&gt;Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Images&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;h3 id=&quot;Local-Images&quot;&gt;Local Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Local-Images&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;You can reference local images and they will be copied and rendered on your blog automatically.  You can include these with the following markdown syntax:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](my_icons/fastai_logo.png)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;/fastpages/images/copied_from_nb/my_icons/fastai_logo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Remote-Images&quot;&gt;Remote Images&lt;a class=&quot;anchor-link&quot; href=&quot;#Remote-Images&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Remote images can be included with the following markdown syntax:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](https://image.flaticon.com/icons/svg/36/36686.svg)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;https://image.flaticon.com/icons/svg/36/36686.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Animated-Gifs&quot;&gt;Animated Gifs&lt;a class=&quot;anchor-link&quot; href=&quot;#Animated-Gifs&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Animated Gifs work, too!&lt;/p&gt;
&lt;p&gt;&lt;code&gt;![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif)&lt;/code&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h3 id=&quot;Captions&quot;&gt;Captions&lt;a class=&quot;anchor-link&quot; href=&quot;#Captions&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;You can include captions with markdown images like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://www.fast.ai/images/fastai_paper/show_batch.png&quot; alt=&quot;&quot; title=&quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h1 id=&quot;Other-Elements&quot;&gt;Other Elements&lt;a class=&quot;anchor-link&quot; href=&quot;#Other-Elements&quot;&gt; &lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Tweetcards&quot;&gt;Tweetcards&lt;a class=&quot;anchor-link&quot; href=&quot;#Tweetcards&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20&lt;/code&gt; will render this:

&lt;center&gt;
    &lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Altair 4.0 is released! &lt;a href=&quot;https://t.co/PCyrIOTcvv&quot;&gt;https://t.co/PCyrIOTcvv&lt;/a&gt;&lt;br /&gt;Try it with:&lt;br /&gt;&lt;br /&gt;  pip install -U altair&lt;br /&gt;&lt;br /&gt;The full list of changes is at &lt;a href=&quot;https://t.co/roXmzcsT58&quot;&gt;https://t.co/roXmzcsT58&lt;/a&gt; ...read on for some highlights. &lt;a href=&quot;https://t.co/vWJ0ZveKbZ&quot;&gt;pic.twitter.com/vWJ0ZveKbZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jake VanderPlas (@jakevdp) &lt;a href=&quot;https://twitter.com/jakevdp/status/1204765621767901185?ref_src=twsrc%5Etfw&quot;&gt;December 11, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Youtube-Videos&quot;&gt;Youtube Videos&lt;a class=&quot;anchor-link&quot; href=&quot;#Youtube-Videos&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; youtube: https://youtu.be/XfoYk_Z5AkI&lt;/code&gt; will render this:

&lt;center&gt;
    &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/XfoYk_Z5AkI&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/center&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Boxes-/-Callouts&quot;&gt;Boxes / Callouts&lt;a class=&quot;anchor-link&quot; href=&quot;#Boxes-/-Callouts&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Typing &lt;code&gt;&amp;gt; Warning: There will be no second warning!&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-error&quot;&gt;
    &lt;svg class=&quot;octicon octicon-alert&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 000 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 00.01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Warning: &lt;/strong&gt;There will be no second warning!
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Important: Pay attention! It's important.&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-warn&quot;&gt;
    &lt;svg class=&quot;octicon octicon-zap&quot; viewBox=&quot;0 0 10 16&quot; version=&quot;1.1&quot; width=&quot;10&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M10 7H6l3-7-9 9h4l-3 7 9-9z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Important: &lt;/strong&gt;Pay attention! It&amp;#8217;s important.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Tip: This is my tip.&lt;/code&gt; will render this:
&lt;div class=&quot;flash flash-success&quot;&gt;
    &lt;svg class=&quot;octicon octicon-checklist&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M16 8.5l-6 6-3-3L8.5 10l1.5 1.5L14.5 7 16 8.5zM5.7 12.2l.8.8H2c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h7c.55 0 1 .45 1 1v6.5l-.8-.8c-.39-.39-1.03-.39-1.42 0L5.7 10.8a.996.996 0 000 1.41v-.01zM4 4h5V3H4v1zm0 2h5V5H4v1zm0 2h3V7H4v1zM3 9H2v1h1V9zm0-2H2v1h1V7zm0-2H2v1h1V5zm0-2H2v1h1V3z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Tip: &lt;/strong&gt;This is my tip.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Note: Take note of this.&lt;/code&gt; will render this:
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;Take note of this.
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;Typing &lt;code&gt;&amp;gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine.&lt;/code&gt; will render in the docs:
&lt;div class=&quot;flash&quot;&gt;
    &lt;svg class=&quot;octicon octicon-info octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;
    &lt;strong&gt;Note: &lt;/strong&gt;A doc link to &lt;a href=&quot;https://www.fast.ai/&quot;&gt;an example website: fast.ai&lt;/a&gt; should also work fine.
&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;Footnotes&quot;&gt;Footnotes&lt;a class=&quot;anchor-link&quot; href=&quot;#Footnotes&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You can have footnotes in notebooks, however the syntax is different compared to markdown documents. &lt;a href=&quot;https://github.com/fastai/fastpages/blob/master/_fastpages_docs/NOTEBOOK_FOOTNOTES.md&quot;&gt;This guide provides more detail about this syntax&lt;/a&gt;, which looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;For example, here is a footnote {% fn 1 %}.
And another {% fn 2 %}
{{ 'This is the footnote.' | fndetail: 1 }}
{{ 'This is the other footnote. You can even have a [link](www.github.com)!' | fndetail: 2 }}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, here is a footnote &lt;sup id=&quot;fnref-1&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn-1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;And another &lt;sup id=&quot;fnref-2&quot; class=&quot;footnote-ref&quot;&gt;&lt;a href=&quot;#fn-2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;div class=&quot;footnotes&quot;&gt;&lt;p id=&quot;fn-1&quot;&gt;1. This is the footnote.&lt;a href=&quot;#fnref-1&quot; class=&quot;footnote footnotes&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;
&lt;div class=&quot;footnotes&quot;&gt;&lt;p id=&quot;fn-2&quot;&gt;2. This is the other footnote. You can even have a &lt;a href=&quot;www.github.com&quot;&gt;link&lt;/a&gt;!&lt;a href=&quot;#fnref-2&quot; class=&quot;footnote footnotes&quot;&gt;&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://datapsyche.github.io/fastpages/images/chart-preview.png" /><media:content medium="image" url="https://datapsyche.github.io/fastpages/images/chart-preview.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">An Example Markdown Post</title><link href="https://datapsyche.github.io/fastpages/markdown/2020/01/14/test-markdown-post.html" rel="alternate" type="text/html" title="An Example Markdown Post" /><published>2020-01-14T00:00:00-06:00</published><updated>2020-01-14T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/markdown/2020/01/14/test-markdown-post</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/markdown/2020/01/14/test-markdown-post.html">&lt;h1 id=&quot;example-markdown-post&quot;&gt;Example Markdown Post&lt;/h1&gt;

&lt;h2 id=&quot;basic-setup&quot;&gt;Basic setup&lt;/h2&gt;

&lt;p&gt;Jekyll requires blog post files to be named according to the following format:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;YEAR-MONTH-DAY-filename.md&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;highlighter-rouge&quot;&gt;YEAR&lt;/code&gt; is a four-digit number, &lt;code class=&quot;highlighter-rouge&quot;&gt;MONTH&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;DAY&lt;/code&gt; are both two-digit numbers, and &lt;code class=&quot;highlighter-rouge&quot;&gt;filename&lt;/code&gt; is whatever file name you choose, to remind yourself what this post is about. &lt;code class=&quot;highlighter-rouge&quot;&gt;.md&lt;/code&gt; is the file extension for markdown files.&lt;/p&gt;

&lt;p&gt;The first line of the file should start with a single hash character, then a space, then your title. This is how you create a &lt;em&gt;level 1 heading&lt;/em&gt; in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line &lt;code class=&quot;highlighter-rouge&quot;&gt;## File names&lt;/code&gt; above.&lt;/p&gt;

&lt;h2 id=&quot;basic-formatting&quot;&gt;Basic formatting&lt;/h2&gt;

&lt;p&gt;You can use &lt;em&gt;italics&lt;/em&gt;, &lt;strong&gt;bold&lt;/strong&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;code font text&lt;/code&gt;, and create &lt;a href=&quot;https://www.markdownguide.org/cheat-sheet/&quot;&gt;links&lt;/a&gt;. Heres a footnote &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Heres a horizontal rule:&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;lists&quot;&gt;Lists&lt;/h2&gt;

&lt;p&gt;Heres a list:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;item 1&lt;/li&gt;
  &lt;li&gt;item 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And a numbered list:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;item 1&lt;/li&gt;
  &lt;li&gt;item 2&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;boxes-and-stuff&quot;&gt;Boxes and stuff&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is a quotation&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;Toast Toast--warning googoo&quot;&gt;
   &lt;span class=&quot;Toast-icon&quot;&gt;&lt;svg class=&quot;octicon octicon-alert&quot; viewBox=&quot;0 0 16 16&quot; version=&quot;1.1&quot; width=&quot;16&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 000 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 00.01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/span&gt;
   &lt;span class=&quot;Toast-content&quot;&gt;You can include alert boxes&lt;/span&gt;
&lt;/div&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;div class=&quot;Toast&quot;&gt;
   &lt;span class=&quot;Toast-icon&quot;&gt;&lt;svg class=&quot;octicon octicon-info&quot; viewBox=&quot;0 0 14 16&quot; version=&quot;1.1&quot; width=&quot;14&quot; height=&quot;16&quot; aria-hidden=&quot;true&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/span&gt;
   &lt;span class=&quot;Toast-content&quot;&gt;You can include info boxes&lt;/span&gt;
&lt;/div&gt;

&lt;h2 id=&quot;images&quot;&gt;Images&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/fastpages/images/logo.png&quot; alt=&quot;&quot; title=&quot;fast.ai's logo&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;p&gt;You can format text and code per usual&lt;/p&gt;

&lt;p&gt;General preformatted text:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Do a thing
do_thing()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Python code and output:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Prints '2'
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Formatting text as shell commands:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hello world&quot;&lt;/span&gt;
./some_script.sh &lt;span class=&quot;nt&quot;&gt;--option&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;value&quot;&lt;/span&gt;
wget https://example.com/cat_photo1.png
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Formatting text as YAML:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;value&lt;/span&gt;
&lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;another_key&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;another&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;value&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;tables&quot;&gt;Tables&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Column 1&lt;/th&gt;
      &lt;th&gt;Column 2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;A thing&lt;/td&gt;
      &lt;td&gt;Another thing&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;tweetcards&quot;&gt;Tweetcards&lt;/h2&gt;

&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Altair 4.0 is released! &lt;a href=&quot;https://t.co/PCyrIOTcvv&quot;&gt;https://t.co/PCyrIOTcvv&lt;/a&gt;&lt;br /&gt;Try it with:&lt;br /&gt;&lt;br /&gt;  pip install -U altair&lt;br /&gt;&lt;br /&gt;The full list of changes is at &lt;a href=&quot;https://t.co/roXmzcsT58&quot;&gt;https://t.co/roXmzcsT58&lt;/a&gt; ...read on for some highlights. &lt;a href=&quot;https://t.co/vWJ0ZveKbZ&quot;&gt;pic.twitter.com/vWJ0ZveKbZ&lt;/a&gt;&lt;/p&gt;&amp;mdash; Jake VanderPlas (@jakevdp) &lt;a href=&quot;https://twitter.com/jakevdp/status/1204765621767901185?ref_src=twsrc%5Etfw&quot;&gt;December 11, 2019&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;This is the footnote.&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html">Example Markdown Post</summary></entry><entry><title type="html">Introduction to Eloquent Javascript</title><link href="https://datapsyche.github.io/fastpages/markdown/2019/03/06/Javascript-Refresher.html" rel="alternate" type="text/html" title="Introduction to Eloquent Javascript" /><published>2019-03-06T00:00:00-06:00</published><updated>2019-03-06T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/markdown/2019/03/06/Javascript%20Refresher</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/markdown/2019/03/06/Javascript-Refresher.html">&lt;h1 id=&quot;eloquent-javascript&quot;&gt;Eloquent Javascript&lt;/h1&gt;

&lt;h4 id=&quot;chapter-1&quot;&gt;Chapter-1&lt;/h4&gt;

&lt;p&gt;Javascript is built into every modern web browser and is available on almost every device. A sample program in javascript looks like.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-(javascript)&quot;&gt;let total = 0, count = 1;
while (count &amp;lt;= 10){
    total + = count;
    count + = 1;
}
console.log(total);
// -&amp;gt; 55
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the same program can also be written as&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)));&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// -&amp;gt; 55&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Javascript was introduced in 1995, as a way to add programs to webpages in Netscape Navigator browser. Javascript is now mostly used in traditional websites to provide various forms of interactivity and cleverness. Javascript is nothing related to java and it was marketing decision to name it similar to highle popular java language. ECMA script standard maintains javascript standards. Javascript are not only used by web browsers but also by databases such as MongoDB and CouchDB use javascript as scripting and query language.&lt;/p&gt;</content><author><name></name></author><summary type="html">Eloquent Javascript</summary></entry><entry><title type="html">Data Mining Map by Saed Sayad</title><link href="https://datapsyche.github.io/fastpages/markdown/2019/01/11/Machine-Learning-Refresher.html" rel="alternate" type="text/html" title="Data Mining Map by Saed Sayad" /><published>2019-01-11T00:00:00-06:00</published><updated>2019-01-11T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/markdown/2019/01/11/Machine-Learning-Refresher</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/markdown/2019/01/11/Machine-Learning-Refresher.html">&lt;h1 id=&quot;data-mining-map-by-saeed-sayad&quot;&gt;Data Mining Map by Saeed Sayad&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Data Science&lt;/strong&gt; can be broadly divided into two approaches &lt;em&gt;explaining the past&lt;/em&gt;  or &lt;em&gt;predicting the future&lt;/em&gt; by means of data analysis. Data Science is a multi disciplinary field that combines statistics, machine learning, artificial intelligence and database technology.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/home/jithin/github/datapsyche.github.io/img/2019-11-11-datascienceMap.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Business have accumulated data over the years and with the help of data science we are able extract valuable knowledge from this data. Lets understand how each field in above diagram contribute to Data Science.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Statistics&lt;/strong&gt; is used in Data Science for collecting , classifying, summarising, organising, analysing and interpreting data. &lt;strong&gt;Artificial Intelligence&lt;/strong&gt; contributes to Data Science by simulating intelligent behaviours from the underlying data. &lt;strong&gt;Machine Learning&lt;/strong&gt; contributes to data science by coming up with algorithms that improve automatically through experience. &lt;strong&gt;Database Technology&lt;/strong&gt; is necessary for collecting, storing and managing data so users can retrieve, add, update or remove data.&lt;/p&gt;

&lt;h5 id=&quot;now-what-do-we-do-in-data-science-&quot;&gt;Now what do we do in Data Science ??&lt;/h5&gt;

&lt;p&gt;In Laymans language we analyse data to &lt;strong&gt;explain the past&lt;/strong&gt; or to &lt;strong&gt;predict the future&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;explaining-the-past&quot;&gt;Explaining the past&lt;/h2&gt;

&lt;p&gt;For explaining the past we need to do Data Exploration - It is all about describing the data by means of statistical and visualization technique. Data Exploration helps in order to bring important aspects of data into focus for further analysis.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Univariate Analysis -  Exploring variables one by one . Variables can be of two types categorical or numerical. Each type of variable has is own recommended way for analysis or for graphical plotting.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Categorical Variables - A categorical or discrete variable has two or more categories (values). There are two types of categorical variables&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;Nominal Variable -  No intrinsic ordering for its categories (eg - Gender)&lt;/li&gt;
          &lt;li&gt;Ordinal Variable - A clear ordering is there (eg - Temperature [low, medium, high]&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;&lt;strong&gt;Frequency tables&lt;/strong&gt; are the best way to analyse such variables&lt;/p&gt;

        &lt;p&gt;&lt;strong&gt;Pie Chart&lt;/strong&gt; and &lt;strong&gt;Bar Chart&lt;/strong&gt; are commonly used for visual analysis.&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/home/jithin/github/datapsyche.github.io/img/Univariate.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Numerical Variables&lt;/strong&gt; - takes any value within a finite  or infinite interval eg:- &lt;em&gt;height, weight, temperature, blood glucose&lt;/em&gt;. There are two types of numerical variables, intervals and ratio.&lt;/p&gt;

        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Interval Variables&lt;/strong&gt; - Values whose differences are interpret able. (&lt;em&gt;temperature in centigrade&lt;/em&gt;). Data in Interval scale can be added or subtracted but cannot be meaningfully multiplied or divided.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Ratio Variable&lt;/strong&gt; - Data in ratio variable has values with a true zero and can be added, subtracted ,multiplied or divided. (eg- &lt;em&gt;weight&lt;/em&gt;)&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;How do we analyse Numerical variables ? Below table describe the various methods to analyse Numerical variable&lt;/p&gt;

        &lt;table&gt;
          &lt;thead&gt;
            &lt;tr&gt;
              &lt;th&gt;Statistics&lt;/th&gt;
              &lt;th&gt;Visualization&lt;/th&gt;
              &lt;th&gt;Equation&lt;/th&gt;
              &lt;th&gt;Description&lt;/th&gt;
            &lt;/tr&gt;
          &lt;/thead&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;Count&lt;/td&gt;
              &lt;td&gt;Histogram&lt;/td&gt;
              &lt;td&gt;&lt;em&gt;N&lt;/em&gt;&lt;/td&gt;
              &lt;td&gt;Number of observations&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Minimum&lt;/td&gt;
              &lt;td&gt;Box Plot&lt;/td&gt;
              &lt;td&gt;&lt;em&gt;Min&lt;/em&gt;&lt;/td&gt;
              &lt;td&gt;smallest value among the observations&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Maximum&lt;/td&gt;
              &lt;td&gt;Box Plot&lt;/td&gt;
              &lt;td&gt;&lt;em&gt;Max&lt;/em&gt;&lt;/td&gt;
              &lt;td&gt;largest value among the observations&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Mean&lt;/td&gt;
              &lt;td&gt;Box Plot&lt;/td&gt;
              &lt;td&gt;&lt;img src=&quot;/home/jithin/github/datapsyche.github.io/img/mean.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
              &lt;td&gt;Sum of values / count&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Median&lt;/td&gt;
              &lt;td&gt;Box Plot&lt;/td&gt;
              &lt;td&gt;&lt;img src=&quot;/home/jithin/github/datapsyche.github.io/img/Median.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
              &lt;td&gt;Middle value below and above lies equal number of values&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Mode&lt;/td&gt;
              &lt;td&gt;Histogram&lt;/td&gt;
              &lt;td&gt;&lt;/td&gt;
              &lt;td&gt;Most frequent value in observation set&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Quantile&lt;/td&gt;
              &lt;td&gt;Box Plot&lt;/td&gt;
              &lt;td&gt;&lt;em&gt;Q~k~&lt;/em&gt;&lt;/td&gt;
              &lt;td&gt;Cut points that divides observations into multiple groups with equal number of values&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Range&lt;/td&gt;
              &lt;td&gt;Box plot&lt;/td&gt;
              &lt;td&gt;&lt;em&gt;Max - Min&lt;/em&gt;&lt;/td&gt;
              &lt;td&gt;Difference between Maximum and minimum&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Variance&lt;/td&gt;
              &lt;td&gt;Histogram&lt;/td&gt;
              &lt;td&gt;&lt;img src=&quot;/home/jithin/github/datapsyche.github.io/img/Variance.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
              &lt;td&gt;Measure of Data Dispersion&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Standard Deviation&lt;/td&gt;
              &lt;td&gt;Histogram&lt;/td&gt;
              &lt;td&gt;&lt;img src=&quot;/home/jithin/github/datapsyche.github.io/img/StDev.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
              &lt;td&gt;Square root of Variance&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Coefficient Of Deviation&lt;/td&gt;
              &lt;td&gt;Histogram&lt;/td&gt;
              &lt;td&gt;&lt;img src=&quot;/home/jithin/github/datapsyche.github.io/img/CV.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
              &lt;td&gt;Measure of Data Dispersion divided by Mean&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Skewness&lt;/td&gt;
              &lt;td&gt;Histogram&lt;/td&gt;
              &lt;td&gt;&lt;img src=&quot;/home/jithin/github/datapsyche.github.io/img/Skewness.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
              &lt;td&gt;Measure of symmetry or asymmetry of data&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;Kurtosis&lt;/td&gt;
              &lt;td&gt;Histogram&lt;/td&gt;
              &lt;td&gt;&lt;/td&gt;
              &lt;td&gt;Measure of whether the data are peaked or flat relative to a normal distribution&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Bivariate Analysis&lt;/strong&gt; - Simultaneous analysis of 2 Variables. Explores the concept of relationship between 2 variables. There are 3 types of bivariate analysis&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Numerical &amp;amp; Numerical&lt;/strong&gt; -
        &lt;ul&gt;
          &lt;li&gt;Scatter Plot is a visual representation of two numerical variables, We can infer patterns from this.&lt;/li&gt;
          &lt;li&gt;Linear Correlation - quantifies the linear relationship between two numerical variables&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Categorical &amp;amp; Categorical&lt;/strong&gt; -
        &lt;ul&gt;
          &lt;li&gt;Stacked Column Chart - Compares the percentage each category from one variable contributes to a total across categories of second variable&lt;/li&gt;
          &lt;li&gt;Combination Charts - two or more different type of charts for each variable (bar chart and chart) to show how one variable is affecting other variable&lt;/li&gt;
          &lt;li&gt;Chi Square Test -Used to determine association between categorical variables, based on differences between expected frequencies (e) and observed frequency (n) in one or more categories in the frequency  table. The test returns a probability for the computed chi square and degree of freedom, probability of 0 means complete dependency between categorical variable and probability of 1 means two categorical variables are completely independent&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Numerical &amp;amp; Categorical&lt;/strong&gt; -
        &lt;ul&gt;
          &lt;li&gt;Line Chart with error Bars -Error Bars show standard Error in that particular Category.&lt;/li&gt;
          &lt;li&gt;Combination Chart - either line or Bar chart ( line for numerical variable and bar for categorical)&lt;/li&gt;
          &lt;li&gt;Z test and T test - Assess averages of two groups are statistically different from each other If probability between Z is small the difference between two averages is more significant. We use T test when number of observation is less than 30&lt;/li&gt;
          &lt;li&gt;Anova test Assess whether the averages of more than two groups are statistically different from each other, Analysis is appropriate for comparing the averages of a numerical variable for more than two categories of a categorical variable.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;predicting-the-future&quot;&gt;Predicting the Future&lt;/h2&gt;

&lt;p&gt;For predicting the future we make use of models. Hence the name Predictive Modeling. Here we try to predict the outcome. if the outcome is Categorical we call it &lt;strong&gt;classification&lt;/strong&gt;, if it is numerical we call it &lt;strong&gt;regression&lt;/strong&gt;. Descriptive modelling or &lt;strong&gt;clustering&lt;/strong&gt; is the assignment of observations into clusters. &lt;strong&gt;Association Rule&lt;/strong&gt; can help us find interesting association among observations.&lt;/p&gt;

&lt;h3 id=&quot;classification-algorithms&quot;&gt;Classification Algorithms&lt;/h3&gt;

&lt;p&gt;Here output variable is categorical. Classification algorithms could be broadly divided into 4 main groups.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Frequency Table Based&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Zero R method - simplest classification method exclusively relies on target and ignores all predictors. ZeroR classifier simply predicts the majority class. It has no predictability power however it is usefull for determining Baseline performance as a benchmark for other classification methods.&lt;/p&gt;

        &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Construct a frequency  table and select its most frequent value.&lt;/code&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;One R method - simple yet accurate classifiaction algorithm that generates one rule for each predictor in the data and then selects the rule with smallest total error as its one rule.
        &lt;pre&gt;&lt;code class=&quot;language-General&quot;&gt;For each predictor,
        For each value of that predictor make a rule as follows:
                Count how often each value of target appears.
                Find the most frequent class
                Make the rule assign that class to this value of the predictor
        Calculate the total error of the rules of each predictor
Choose the predictor with smallest total error
&lt;/code&gt;&lt;/pre&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Naive Bayes Method -  Based on Naive Bayes Theorem with independence assumption between predictors. Naive Bayes model is easy to build, useful for large data set. Naive Bayes often useful and is widely used as it outperforms classification methods.
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(c/x) = (P(x/c)*P(c))/P(x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(c/x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; - Posterior Probability&lt;/p&gt;

        &lt;p&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(x/c)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; - Likelihood&lt;/p&gt;

        &lt;p&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(c)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; - Class probability&lt;/p&gt;

        &lt;p&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(x)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; - Predictor Prior Probability&lt;/p&gt;

        &lt;span class=&quot;katex-display&quot;&gt;&lt;span class=&quot;katex&quot;&gt;&lt;span class=&quot;katex-mathml&quot;&gt;&lt;math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;X&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mtext&gt;&lt;/mtext&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mtext&gt;&lt;/mtext&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mtext&gt;&lt;/mtext&gt;&lt;mn&gt;2&lt;/mn&gt;&lt;mtext&gt;&lt;/mtext&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;.&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mtext&gt;&lt;/mtext&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;mtext&gt;&lt;/mtext&gt;&lt;mi mathvariant=&quot;normal&quot;&gt;/&lt;/mi&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;mo&gt;&lt;/mo&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding=&quot;application/x-tex&quot;&gt;P(c/X)  = P(x~1~/C) * P(x~2~/C) x ....P(x~n~/C) * P(C)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&quot;katex-html&quot; aria-hidden=&quot;true&quot;&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07847em;&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mrel&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2777777777777778em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mspace nobreak&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;mspace nobreak&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mspace nobreak&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;mspace nobreak&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;mspace nobreak&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;mspace nobreak&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mbin&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mspace&quot; style=&quot;margin-right:0.2222222222222222em;&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;base&quot;&gt;&lt;span class=&quot;strut&quot; style=&quot;height:1em;vertical-align:-0.25em;&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.13889em;&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;mopen&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mord mathdefault&quot; style=&quot;margin-right:0.07153em;&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;mclose&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Data Mining Map by Saeed Sayad</summary></entry><entry><title type="html">Introduction to Siamese Networks</title><link href="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Siamese-Recurrent-Architectures-for-Learning-Sentence-Similarity.html" rel="alternate" type="text/html" title="Introduction to Siamese Networks" /><published>2019-01-10T00:00:00-06:00</published><updated>2019-01-10T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/markdown/2019/01/10/Siamese-Recurrent-Architectures-for-Learning-Sentence-Similarity</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Siamese-Recurrent-Architectures-for-Learning-Sentence-Similarity.html">&lt;h1 id=&quot;siamese-recurrent-architectures-for-learning-sentence-similarity&quot;&gt;Siamese Recurrent Architectures for Learning Sentence Similarity&lt;/h1&gt;

&lt;p&gt;Paper by Jonas Mueller &amp;amp; Aditya Thyagarajan  - http://www.mit.edu/~jonasm/info/MuellerThyagarajan_AAAI16.pdf&lt;/p&gt;

&lt;h4 id=&quot;introduction&quot;&gt;Introduction&lt;/h4&gt;

&lt;p&gt;Mikolov demonstrated the effectiveness of neural word representations for analogies and other NLP tasks (2013), ever since interest shifted towards extensions of these ideas beyond the individual word-level to larger bodies of text like sentences where a mapping is learned to represent each sentence as a fixed length vector (Kiros 2015 and Mikolov 2014). RNNs are naturally suited for variable length inputs like sentences, LSTM is the most preferred type of RNNs. RNNs are Turing complete optimization of the weight matrices is difficult due to the backpropagated vanishing gradients hence LSTM was preferred.&lt;/p&gt;

&lt;p&gt;Here we consider a supervised learning setting where each training example consists of a pair of sequences of fixed-size vectors along a single label y for the pair. sequences may be of different lengths. The task here can be considered as scoring similarity between sentences given example pairs whose semantic similarity labelled .&lt;/p&gt;

&lt;h4 id=&quot;related-work&quot;&gt;Related Work&lt;/h4&gt;</content><author><name></name></author><summary type="html">Siamese Recurrent Architectures for Learning Sentence Similarity Paper by Jonas Mueller &amp;amp; Aditya Thyagarajan - http://www.mit.edu/~jonasm/info/MuellerThyagarajan_AAAI16.pdf Introduction Mikolov demonstrated the effectiveness of neural word representations for analogies and other NLP tasks (2013), ever since interest shifted towards extensions of these ideas beyond the individual word-level to larger bodies of text like sentences where a mapping is learned to represent each sentence as a fixed length vector (Kiros 2015 and Mikolov 2014). RNNs are naturally suited for variable length inputs like sentences, LSTM is the most preferred type of RNNs. RNNs are Turing complete optimization of the weight matrices is difficult due to the backpropagated vanishing gradients hence LSTM was preferred. Here we consider a supervised learning setting where each training example consists of a pair of sequences of fixed-size vectors along a single label y for the pair. sequences may be of different lengths. The task here can be considered as scoring similarity between sentences given example pairs whose semantic similarity labelled . Related Work</summary></entry><entry><title type="html">Word Embedding Literature Review</title><link href="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Word-Embeddings-Literature-Review.html" rel="alternate" type="text/html" title="Word Embedding Literature Review" /><published>2019-01-10T00:00:00-06:00</published><updated>2019-01-10T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/markdown/2019/01/10/Word-Embeddings-Literature-Review</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Word-Embeddings-Literature-Review.html">&lt;h1 id=&quot;word-embeddings---literature-review&quot;&gt;Word Embeddings - Literature Review&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Word embeddings are representations of a document library capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words.&lt;/li&gt;
  &lt;li&gt;Vector representation of a particular word.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;How to create a word Embedding ?&lt;/strong&gt; - &lt;strong&gt;Word2vec&lt;/strong&gt; is the most popular technique to learn word embeddings, it is using shallow neural network.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why do we need Word Embedding ?&lt;/strong&gt; - In One hot encoding all the words are independent of each other. Word Embedding aims to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of data. The underlying principle is that a word is characterized by the company it keeps.&lt;/p&gt;

&lt;h3 id=&quot;paper-reading---evaluation-of--sentence-embedding-in-downstream-and-linguistic-probing-tasks&quot;&gt;Paper Reading - Evaluation of  sentence embedding in downstream and linguistic probing tasks.&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;by Christian S Perone, Roberto Silvera, Thomas Paula&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Word Embedding ranges from Neural Probablistic Language Model, Word2vec, GloVe, and ELMO. Most of them rely on distributional linguistic hypothesis but differ on assumption of how meaning or context are modeled to produce the word embeddings. Word embeddings provide high quality representation for words but representing sentences, paragraphs is still an open research.&lt;/p&gt;

&lt;p&gt;Most common approach is &lt;strong&gt;Bag of Words&lt;/strong&gt; model. Here we create a Bag of words word vector using simple arithmetic mean of the embeddings for the words in a sentence along the words dimension. Though the approach seems trivial and limited lot of improvements have taken place in Bag of Words model by using weighted averages and modifying them using singular value decomposition (SVD) the method is called &lt;strong&gt;smooth inverse frequency&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;word embedding based on Encoder / Decoder architectures - &lt;strong&gt;Skip Thought&lt;/strong&gt; - a skip gram model from word2vec was abstracted to form sentence level encoder trained on self supervised fashion.&lt;/p&gt;</content><author><name></name></author><summary type="html">Word Embeddings - Literature Review Word embeddings are representations of a document library capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words. Vector representation of a particular word. How to create a word Embedding ? - Word2vec is the most popular technique to learn word embeddings, it is using shallow neural network. Why do we need Word Embedding ? - In One hot encoding all the words are independent of each other. Word Embedding aims to quantify and categorize semantic similarities between linguistic items based on their distributional properties in large samples of data. The underlying principle is that a word is characterized by the company it keeps. Paper Reading - Evaluation of sentence embedding in downstream and linguistic probing tasks. by Christian S Perone, Roberto Silvera, Thomas Paula Word Embedding ranges from Neural Probablistic Language Model, Word2vec, GloVe, and ELMO. Most of them rely on distributional linguistic hypothesis but differ on assumption of how meaning or context are modeled to produce the word embeddings. Word embeddings provide high quality representation for words but representing sentences, paragraphs is still an open research. Most common approach is Bag of Words model. Here we create a Bag of words word vector using simple arithmetic mean of the embeddings for the words in a sentence along the words dimension. Though the approach seems trivial and limited lot of improvements have taken place in Bag of Words model by using weighted averages and modifying them using singular value decomposition (SVD) the method is called smooth inverse frequency. word embedding based on Encoder / Decoder architectures - Skip Thought - a skip gram model from word2vec was abstracted to form sentence level encoder trained on self supervised fashion.</summary></entry><entry><title type="html">Matching Resumes to Jobs via Deep Siamese Networks</title><link href="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Matching-Resumes-to-Job-Via-Deep-Siamese-Networks.html" rel="alternate" type="text/html" title="Matching Resumes to Jobs via Deep Siamese Networks" /><published>2019-01-10T00:00:00-06:00</published><updated>2019-01-10T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/markdown/2019/01/10/Matching-Resumes-to-Job-%20Via-Deep-Siamese-Networks</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Matching-Resumes-to-Job-Via-Deep-Siamese-Networks.html">&lt;h1 id=&quot;matching-resumes-to-jobs-via-deep-siamese-network&quot;&gt;Matching Resumes to Jobs via Deep Siamese Network&lt;/h1&gt;

&lt;h4 id=&quot;introduction&quot;&gt;Introduction&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Given a collection of semi structured job description J and some known matched and unmatched resume / job description pairs &lt;em&gt;&amp;lt;r,j&amp;gt;&lt;/em&gt; the task is to retrieve matching job descriptions for any existing or new resume &lt;em&gt;r&lt;/em&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Traditional engines fail to understand the underlying semantic meanings of different resumes and have not kept pace with recent progress in machine learning and natural language processing (NLP) techniques.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;These solutions are generally driven by manually engineered features and set of rules with predefined weights to keywords which lean to an inefficient and ineffective search experience for job candidates and not generally scalable.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Text based tasks rely heavily on representations that could be effectively learned. such representation must capture the underlying semantics among textual elements, where textual elements can be sequences, words or characters.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;State of the art models like Bag of words and TF-IDF are effective in many NLP tasks, in the context of understanding the underlying semantics they are inefficient due to their inherent term specificity.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Models like Glove, Word2Vec are less effective at document level.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Siamese Networks possess the capability of learning a similarity metric from the available training records. Here Siamese networks posses the capability of learning a similarity metric from the available training records. here CNN convolutional neural networks with a contrastive loss energy function joining the twin network at the top. The twin network share the weights with eachother&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;proposed-approach&quot;&gt;Proposed Approach&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Consists of a pair of identical CNN that contains repeating convolution, Max pooling and leaky rectified linear unit layers with a fully connected layer at the top.&lt;/li&gt;
  &lt;li&gt;CNN is used because any part of text in resumes and job description can influence the semantics of the word. In order to effectively capture the CNN should see the entire input at once hence CNN is used, Use of CNN could be contrasted by use of LSTM networks. LSTM usually read from left to right hence Bidirectional LSTM are required. which is even more computationally intensive. hence CNN was considered. CNN grows a larger receptive field as we stack more and more layers. It gives a desired effect in a controllable fashion with a low computational cost.&lt;/li&gt;
  &lt;li&gt;CNN gives a non linear projection to the resumes and JD in semantic space. The semantic vectors yielded from CNN are connected to a layer measuring similarity between resume and JD. The contrastive loss function combines the measured distance and the label. The gradient of the loss function with respect to weights and biases shared by subnetworks are computed using back propagation.&lt;/li&gt;
  &lt;li&gt;Parameter sharing is the highlight of siamese networks. Training the network with a shared set of parameter not only reduce number of parameter but also represent consistency of the representation of JD and Resume in a semantic space. The shared parameters are learned with the aim to minimize / Maximize the distance between resumes and JD.  Doc2Vec is used for document embedding of resume and jd. This vector representation is given as input to the network.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experiments&quot;&gt;Experiments&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Baseline Method&lt;/strong&gt; - 6 commonly used representations 1) &lt;strong&gt;Word n_grams&lt;/strong&gt; 2) &lt;strong&gt;TF-IDF&lt;/strong&gt; - Baseline methods to compare with due to their effectiveness in variety of NLP tasks 3) &lt;strong&gt;BOW&lt;/strong&gt; : The word frequency from training text is selected and count of each word is used as features. 4) &lt;strong&gt;Bag of Means&lt;/strong&gt; : The avearage word2vec embedding of the training data is used as a feature set. 5) &lt;strong&gt;Doc2Vec&lt;/strong&gt; : An unsupervised algorithm that learns fixed-length feature representation from variable length pieces of text. 6) &lt;strong&gt;CNN&lt;/strong&gt; . Cosine Similarity was the final step with all these baseline models in order to find the similarity of &amp;lt;r,j&amp;gt; pair. The Value of threshold for cosine similarity is determined by grid search on values.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dataset and Experimental Setting&lt;/strong&gt; -&lt;/p&gt;

&lt;p&gt;Dataset consists of 1314 resumes and a set of 3809 JDs. hence generating a pair of 5,005,026 distinct &amp;lt;r,j&amp;gt; pair with label as 0 or 1. Annotated the corpus in semi supervised fashion. First few were manually annotated by interns. Each resume and JD was preprocessed by &lt;em&gt;lower casing&lt;/em&gt;, &lt;em&gt;stemming&lt;/em&gt; and &lt;em&gt;special character removal&lt;/em&gt;. Performed training in &lt;strong&gt;batches of size 128&lt;/strong&gt; . &lt;strong&gt;length of semantic vector was 256&lt;/strong&gt;.  &lt;strong&gt;depth of CNN was 4&lt;/strong&gt;, &lt;strong&gt;Kernel width of max pooling is 100&lt;/strong&gt; and &lt;strong&gt;convolution is 10&lt;/strong&gt; and &lt;strong&gt;learning rate was set to 0.01&lt;/strong&gt;. &lt;strong&gt;Adam optimization&lt;/strong&gt; is used to update parameters of the subnetworks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Result and Analysis&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Table shows the result of the various methods on task of matching resumes to jobs. Compare with 6 baseline methods. Performance of proposed siamese adaptation of CNN is significantly better than a all of the baseline models.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Matching Resumes to Jobs via Deep Siamese Network Introduction Given a collection of semi structured job description J and some known matched and unmatched resume / job description pairs &amp;lt;r,j&amp;gt; the task is to retrieve matching job descriptions for any existing or new resume r. Traditional engines fail to understand the underlying semantic meanings of different resumes and have not kept pace with recent progress in machine learning and natural language processing (NLP) techniques. These solutions are generally driven by manually engineered features and set of rules with predefined weights to keywords which lean to an inefficient and ineffective search experience for job candidates and not generally scalable. Text based tasks rely heavily on representations that could be effectively learned. such representation must capture the underlying semantics among textual elements, where textual elements can be sequences, words or characters. State of the art models like Bag of words and TF-IDF are effective in many NLP tasks, in the context of understanding the underlying semantics they are inefficient due to their inherent term specificity. Models like Glove, Word2Vec are less effective at document level. Siamese Networks possess the capability of learning a similarity metric from the available training records. Here Siamese networks posses the capability of learning a similarity metric from the available training records. here CNN convolutional neural networks with a contrastive loss energy function joining the twin network at the top. The twin network share the weights with eachother Proposed Approach Consists of a pair of identical CNN that contains repeating convolution, Max pooling and leaky rectified linear unit layers with a fully connected layer at the top. CNN is used because any part of text in resumes and job description can influence the semantics of the word. In order to effectively capture the CNN should see the entire input at once hence CNN is used, Use of CNN could be contrasted by use of LSTM networks. LSTM usually read from left to right hence Bidirectional LSTM are required. which is even more computationally intensive. hence CNN was considered. CNN grows a larger receptive field as we stack more and more layers. It gives a desired effect in a controllable fashion with a low computational cost. CNN gives a non linear projection to the resumes and JD in semantic space. The semantic vectors yielded from CNN are connected to a layer measuring similarity between resume and JD. The contrastive loss function combines the measured distance and the label. The gradient of the loss function with respect to weights and biases shared by subnetworks are computed using back propagation. Parameter sharing is the highlight of siamese networks. Training the network with a shared set of parameter not only reduce number of parameter but also represent consistency of the representation of JD and Resume in a semantic space. The shared parameters are learned with the aim to minimize / Maximize the distance between resumes and JD. Doc2Vec is used for document embedding of resume and jd. This vector representation is given as input to the network. Experiments Baseline Method - 6 commonly used representations 1) Word n_grams 2) TF-IDF - Baseline methods to compare with due to their effectiveness in variety of NLP tasks 3) BOW : The word frequency from training text is selected and count of each word is used as features. 4) Bag of Means : The avearage word2vec embedding of the training data is used as a feature set. 5) Doc2Vec : An unsupervised algorithm that learns fixed-length feature representation from variable length pieces of text. 6) CNN . Cosine Similarity was the final step with all these baseline models in order to find the similarity of &amp;lt;r,j&amp;gt; pair. The Value of threshold for cosine similarity is determined by grid search on values. Dataset and Experimental Setting - Dataset consists of 1314 resumes and a set of 3809 JDs. hence generating a pair of 5,005,026 distinct &amp;lt;r,j&amp;gt; pair with label as 0 or 1. Annotated the corpus in semi supervised fashion. First few were manually annotated by interns. Each resume and JD was preprocessed by lower casing, stemming and special character removal. Performed training in batches of size 128 . length of semantic vector was 256. depth of CNN was 4, Kernel width of max pooling is 100 and convolution is 10 and learning rate was set to 0.01. Adam optimization is used to update parameters of the subnetworks. Result and Analysis Table shows the result of the various methods on task of matching resumes to jobs. Compare with 6 baseline methods. Performance of proposed siamese adaptation of CNN is significantly better than a all of the baseline models. </summary></entry><entry><title type="html">Learning Text Similarity with Siamese Recurrent Networks</title><link href="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Learning-Text-Similarity-with-Siamese-Networks.html" rel="alternate" type="text/html" title="Learning Text Similarity with Siamese Recurrent Networks" /><published>2019-01-10T00:00:00-06:00</published><updated>2019-01-10T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/markdown/2019/01/10/Learning-Text-Similarity-with-Siamese-Networks</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Learning-Text-Similarity-with-Siamese-Networks.html">&lt;h1 id=&quot;learning-text-similarity-with-siamese-recurrent-networks&quot;&gt;Learning Text Similarity with Siamese Recurrent Networks&lt;/h1&gt;

&lt;p&gt;Authors - Paul Neculoiu, Maarten Versteegh and Mihai Rotaru.&lt;/p&gt;

&lt;p&gt;Link to the Paper  - http://www.aclweb.org/anthology/W16-16#page=162&lt;/p&gt;

&lt;h4 id=&quot;abstract&quot;&gt;Abstract&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Presents a deep architecture for learning similarity metric on variable length character sequences.&lt;/li&gt;
  &lt;li&gt;Model combines a stack of character-level bidirectional LSTMs with a Siamese architecture.&lt;/li&gt;
  &lt;li&gt;Learns to project variable length strings into a fixed dimensional embedding space by using only information about similarity between pairs of strings.&lt;/li&gt;
  &lt;li&gt;Model could be applied to task of job title normalization based on a manually annotated taxonomy. model learns a representation that is selective to differences in the input reflect semantic differences (eg:- Java developer vs HR manager) but also invariant to non semantic string differences (eg- Java developer vs Java programmer)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;introduction&quot;&gt;Introduction&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Representation that express semantic similarity and dissimilarity between textual elements is important in NLP.
    &lt;ul&gt;
      &lt;li&gt;Word similarity models (Mikolov 2013) is applied in diverse settings such as sentiment analysis and recommender system.&lt;/li&gt;
      &lt;li&gt;Semantic textual similarity is used in automatic summarization (Ponzanelli 2015), debate analysis (Boltuzic and Snajder 2015) and paraphrase detection (Socher 2011).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Measuring semantic similarity between texts is necessary for Information Extraction (IE). This process is also called Normalization ie. to put pieces of information in standard format. eg:- 12pm, noon, 12:00h all should map to same representation. Normalization is essential for retrieving actionable information from free unstructured text.&lt;/li&gt;
  &lt;li&gt;This paper presents a system for job title normalization. task here is to receive an input string and map it to one of a finite set of job codes which were predefined externally. It could be considered as a highly Multi-class classification problem, but here the focus is on learning representation of the strings such that synonymous job titles are close together.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;related-work&quot;&gt;Related Work&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Representation learning through neural network (Auto encoders, Hinton 2006)  is invariant to differences in the input that do not matter for that task and selective to differences.&lt;/li&gt;
  &lt;li&gt;Siamese network (Bromley 1993) is an architecture for non linear metric learning with similarity information. The network naturally learns representations that reveals the invariance and selectivity through explicit information about similarity between pairs of object. Siamese network learns an invariant and selective representation directly through the use of similarity and dissimilarity information.&lt;/li&gt;
  &lt;li&gt;An Autoencoder learns invariance through added noise and dimensionality reduction in the bottleneck layer and selectivity through the condition that the input should be reproduced by the decoding part of the network.&lt;/li&gt;
  &lt;li&gt;Siamese architecture was originally applied to signature verification (Bromley 1993) and has been used in Vision application. Siamese convolutional networks are used for face verification (Chopra 2005) and dimensionality reduction on image features (Hadsell 2006). They have been also used for diverse tasks as unsupervised acoustic modelling (Synnaeve 2014), Learning food preference (Yang 2015), Scene detection (Baraldi, 2015). In NLP Siamese network with convolutional layers have been applied to matching sentences (Hu 2014) and for learning semantic entailment (Mueller 2016).&lt;/li&gt;
  &lt;li&gt;Job Title Normalization is framed as a classification task (Javed 2014)  as it has large number of classes. Multi stage classifier have shown good results. But there are disadvantages to this approach
    &lt;ul&gt;
      &lt;li&gt;Expense of data acquisition for training number of classes will exponentially increase the data requirement.&lt;/li&gt;
      &lt;li&gt;Once a classification error is identified, we need to retrain the entire classifier with new sample added to correct the class&lt;/li&gt;
      &lt;li&gt;Using traditional classifier do not allow for transfer learning.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Use of String similarity measure to classify input strings here the advantage is there is no need to train the system hence improvement can be made by adding job title strings to the data.&lt;/li&gt;
  &lt;li&gt;Modeling similarity directly based on pairs of inputs Siamese networks lend themselves well to the semantic invariance present in job title normalization.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;siamese-recurrent-neural-network&quot;&gt;Siamese Recurrent Neural Network&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Recurrent Neural Networks are neural networks adapted for sequence data. LSTM variant of RNN has particularly had success in tasks related to natural language processing like text classification and language translation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Bi directional RNN incorporate both future and past context by running the reverse f input through a separate RNN. The output of combined model at each time step is simply the concatenation of outputs from the forward and backward networks.&lt;/li&gt;
  &lt;li&gt;Siamese networks are dual branch networks with tied weights, they consist of the same network copied and merged with an energy function. The training set for Siamese network consists of triplets (x1,x2 and y) where x1 and x2 are character sequences and y indicates whether x1 and x2 are similar or dissimilar (0 or 1). The aim of training is to minimize the distance in an embedding space between similar pairs and maximize the distance between dissimilar pairs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;contrastive-loss-function&quot;&gt;Contrastive Loss Function&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The Network contains 4 layers of Bidirectional LSTM nodes. the activations at each time step of the final BLSTM are averaged to produce a fixed dimensional output. This output is projected through a single densely connected feed forward layer.  Energy of the model E is the cosine similarity between embeddings of x1 and x2.&lt;/li&gt;
  &lt;li&gt;The Network used has 4 BLSTM layers with 64 dimensional Hidden vectors h and memory c. there are connections at each time step between layers. Outputs of the last layer are averaged over time and this 128 dimensional vector is used as input to a dense feed forward layer.&lt;/li&gt;
  &lt;li&gt;The input strings are padded to produce a sequence of 100 characters with input string randomly placed in this sequence. The parameters of the model are optimized using Adam method and trained until convergence. Dropout technique (Srivastava 2014) on recurrent units and between layers (probability .4) is done to prevent overfitting.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;experiment&quot;&gt;Experiment&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Small dataset based on handmade taxonomy of job titles is used. After each experiment the dataset is augmented by adding new source of variance.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Baseline&lt;/strong&gt; - ngram matcher (Daelemans 2004). given an input string, this matcher looks up closest neighbour from base taxonomy by maximizing a similarity scoring function. The matcher subsequently labels input string with neighbours group label.  This similarity function has the properties that it is easy to compute and doesnt require any learning and is particularly insensitive to appending extra words in the input string.&lt;/li&gt;
  &lt;li&gt;Here the test set consists of pairs of strings, the first of which is the input string and the second a target group label from the base taxonomy. The network model projects the input string into the embedding space and searched for its nearest neighbor under cosine distance from the base taxonomy. The test records a hit only if the neighbors group label matches the target.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;data-and-data-augmentation&quot;&gt;Data and Data Augmentation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Handmade Job Title taxonomy partition set of 19,927 job titles into 4,431 groups. Job Titles were manually and semi automatically collected from resumes and vacancy postings. Each was manually assigned a group such that job titles in a group are close together.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The wide variety of different semantic relations between and within groups is considered as an asset to be exploited by the model.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The groups are not equal in size largest group has 130 job titles and smallest group has just one. The long tail may affect the models ability to accurately learn to represent smallest group.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;4 stage process starting from base taxonomy of job titles at each stage an augmentation of data which focuses on a particular property and a test that probes the model for behavior related to that property. each stage build on next stage hence previous augmentations are included.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The dataset consists of pairs of strings sampled from the taxonomy in a 4:1 ratio of between class (negative pairs) to within-class (positive pairs)&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Testing Criteria&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Typo and Spelling invariance&lt;/em&gt; - Slight differences in spelling from taxonomy should be intelligently picked. to induce this invariance we augment the base taxonomy by extending it with positive sample pairs consisting of job title strings and the same string but with 20% characters randomly substituted and 5% deleted.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Synonyms&lt;/em&gt; - Model should be invariant to synonym substitution we augment the data set by substituting words in job titles by synonyms. first source is a manually constructed job title synonym set consisting of around 1100 job titles each with between 1 and 10 synonyms. Second source is by induction the complements of the matching strings from a synonym candidate.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Extra Words&lt;/em&gt;  - To be useful  model should be invariant to the present of additional words.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Feedback&lt;/em&gt; - Model should be corrigible. we should be able to append the model when it performs badly.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;result&quot;&gt;Result&lt;/h4&gt;

&lt;p&gt;Comparison was done with baseline n-gram system and proposed neural network models on the four tests. Both n-gram matching system and the proposed model have near complete invariance to the simple typos.&lt;/p&gt;

&lt;h4 id=&quot;discussions&quot;&gt;Discussions&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;A model architecture for learning text similarity based on Siamese recurrent neural networks is presented. This architecture learns a series of embedding spaces based on specific augmentation of the dataset used to train the model. The embedding spaces captured important invariances of the input, the model was invariant to spelling variations, synonym replacements and superfluous words.&lt;/li&gt;
  &lt;li&gt;The ability of the system to learn invariances are due the contrastive loss function combined with the stack of recurrent layers. Using separate loss functions for similar and dissimilar samples helps the model maintain selectivity while learning invariances over different sources of variability.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;further-improvements&quot;&gt;Further Improvements&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Incorporating convolutional layers in addition to the recurrent layers.&lt;/li&gt;
  &lt;li&gt;Investigating a triplet loss function instead of contrastive loss used in this study&lt;/li&gt;
  &lt;li&gt;Comparison to a stronger baseline would serve further development.&lt;/li&gt;
  &lt;li&gt;Job Title taxonomy used in the current study exhibits a hierarchical structure that is not fully exploited. further research could attempt to learn a single embedding which would preserve the separation between groups at different levels of hierarchy.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Learning Text Similarity with Siamese Recurrent Networks Authors - Paul Neculoiu, Maarten Versteegh and Mihai Rotaru. Link to the Paper - http://www.aclweb.org/anthology/W16-16#page=162 Abstract Presents a deep architecture for learning similarity metric on variable length character sequences. Model combines a stack of character-level bidirectional LSTMs with a Siamese architecture. Learns to project variable length strings into a fixed dimensional embedding space by using only information about similarity between pairs of strings. Model could be applied to task of job title normalization based on a manually annotated taxonomy. model learns a representation that is selective to differences in the input reflect semantic differences (eg:- Java developer vs HR manager) but also invariant to non semantic string differences (eg- Java developer vs Java programmer) Introduction Representation that express semantic similarity and dissimilarity between textual elements is important in NLP. Word similarity models (Mikolov 2013) is applied in diverse settings such as sentiment analysis and recommender system. Semantic textual similarity is used in automatic summarization (Ponzanelli 2015), debate analysis (Boltuzic and Snajder 2015) and paraphrase detection (Socher 2011). Measuring semantic similarity between texts is necessary for Information Extraction (IE). This process is also called Normalization ie. to put pieces of information in standard format. eg:- 12pm, noon, 12:00h all should map to same representation. Normalization is essential for retrieving actionable information from free unstructured text. This paper presents a system for job title normalization. task here is to receive an input string and map it to one of a finite set of job codes which were predefined externally. It could be considered as a highly Multi-class classification problem, but here the focus is on learning representation of the strings such that synonymous job titles are close together. Related Work Representation learning through neural network (Auto encoders, Hinton 2006) is invariant to differences in the input that do not matter for that task and selective to differences. Siamese network (Bromley 1993) is an architecture for non linear metric learning with similarity information. The network naturally learns representations that reveals the invariance and selectivity through explicit information about similarity between pairs of object. Siamese network learns an invariant and selective representation directly through the use of similarity and dissimilarity information. An Autoencoder learns invariance through added noise and dimensionality reduction in the bottleneck layer and selectivity through the condition that the input should be reproduced by the decoding part of the network. Siamese architecture was originally applied to signature verification (Bromley 1993) and has been used in Vision application. Siamese convolutional networks are used for face verification (Chopra 2005) and dimensionality reduction on image features (Hadsell 2006). They have been also used for diverse tasks as unsupervised acoustic modelling (Synnaeve 2014), Learning food preference (Yang 2015), Scene detection (Baraldi, 2015). In NLP Siamese network with convolutional layers have been applied to matching sentences (Hu 2014) and for learning semantic entailment (Mueller 2016). Job Title Normalization is framed as a classification task (Javed 2014) as it has large number of classes. Multi stage classifier have shown good results. But there are disadvantages to this approach Expense of data acquisition for training number of classes will exponentially increase the data requirement. Once a classification error is identified, we need to retrain the entire classifier with new sample added to correct the class Using traditional classifier do not allow for transfer learning. Use of String similarity measure to classify input strings here the advantage is there is no need to train the system hence improvement can be made by adding job title strings to the data. Modeling similarity directly based on pairs of inputs Siamese networks lend themselves well to the semantic invariance present in job title normalization. Siamese Recurrent Neural Network Recurrent Neural Networks are neural networks adapted for sequence data. LSTM variant of RNN has particularly had success in tasks related to natural language processing like text classification and language translation. Bi directional RNN incorporate both future and past context by running the reverse f input through a separate RNN. The output of combined model at each time step is simply the concatenation of outputs from the forward and backward networks. Siamese networks are dual branch networks with tied weights, they consist of the same network copied and merged with an energy function. The training set for Siamese network consists of triplets (x1,x2 and y) where x1 and x2 are character sequences and y indicates whether x1 and x2 are similar or dissimilar (0 or 1). The aim of training is to minimize the distance in an embedding space between similar pairs and maximize the distance between dissimilar pairs. Contrastive Loss Function The Network contains 4 layers of Bidirectional LSTM nodes. the activations at each time step of the final BLSTM are averaged to produce a fixed dimensional output. This output is projected through a single densely connected feed forward layer. Energy of the model E is the cosine similarity between embeddings of x1 and x2. The Network used has 4 BLSTM layers with 64 dimensional Hidden vectors h and memory c. there are connections at each time step between layers. Outputs of the last layer are averaged over time and this 128 dimensional vector is used as input to a dense feed forward layer. The input strings are padded to produce a sequence of 100 characters with input string randomly placed in this sequence. The parameters of the model are optimized using Adam method and trained until convergence. Dropout technique (Srivastava 2014) on recurrent units and between layers (probability .4) is done to prevent overfitting. Experiment Small dataset based on handmade taxonomy of job titles is used. After each experiment the dataset is augmented by adding new source of variance. Baseline - ngram matcher (Daelemans 2004). given an input string, this matcher looks up closest neighbour from base taxonomy by maximizing a similarity scoring function. The matcher subsequently labels input string with neighbours group label. This similarity function has the properties that it is easy to compute and doesnt require any learning and is particularly insensitive to appending extra words in the input string. Here the test set consists of pairs of strings, the first of which is the input string and the second a target group label from the base taxonomy. The network model projects the input string into the embedding space and searched for its nearest neighbor under cosine distance from the base taxonomy. The test records a hit only if the neighbors group label matches the target. Data and Data Augmentation Handmade Job Title taxonomy partition set of 19,927 job titles into 4,431 groups. Job Titles were manually and semi automatically collected from resumes and vacancy postings. Each was manually assigned a group such that job titles in a group are close together. The wide variety of different semantic relations between and within groups is considered as an asset to be exploited by the model. The groups are not equal in size largest group has 130 job titles and smallest group has just one. The long tail may affect the models ability to accurately learn to represent smallest group. 4 stage process starting from base taxonomy of job titles at each stage an augmentation of data which focuses on a particular property and a test that probes the model for behavior related to that property. each stage build on next stage hence previous augmentations are included. The dataset consists of pairs of strings sampled from the taxonomy in a 4:1 ratio of between class (negative pairs) to within-class (positive pairs) Testing Criteria Typo and Spelling invariance - Slight differences in spelling from taxonomy should be intelligently picked. to induce this invariance we augment the base taxonomy by extending it with positive sample pairs consisting of job title strings and the same string but with 20% characters randomly substituted and 5% deleted. Synonyms - Model should be invariant to synonym substitution we augment the data set by substituting words in job titles by synonyms. first source is a manually constructed job title synonym set consisting of around 1100 job titles each with between 1 and 10 synonyms. Second source is by induction the complements of the matching strings from a synonym candidate. Extra Words - To be useful model should be invariant to the present of additional words. Feedback - Model should be corrigible. we should be able to append the model when it performs badly. Result Comparison was done with baseline n-gram system and proposed neural network models on the four tests. Both n-gram matching system and the proposed model have near complete invariance to the simple typos. Discussions A model architecture for learning text similarity based on Siamese recurrent neural networks is presented. This architecture learns a series of embedding spaces based on specific augmentation of the dataset used to train the model. The embedding spaces captured important invariances of the input, the model was invariant to spelling variations, synonym replacements and superfluous words. The ability of the system to learn invariances are due the contrastive loss function combined with the stack of recurrent layers. Using separate loss functions for similar and dissimilar samples helps the model maintain selectivity while learning invariances over different sources of variability. Further Improvements Incorporating convolutional layers in addition to the recurrent layers. Investigating a triplet loss function instead of contrastive loss used in this study Comparison to a stronger baseline would serve further development. Job Title taxonomy used in the current study exhibits a hierarchical structure that is not fully exploited. further research could attempt to learn a single embedding which would preserve the separation between groups at different levels of hierarchy.</summary></entry><entry><title type="html">Doc2Vec Summary</title><link href="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Doc2Vec-Paper.html" rel="alternate" type="text/html" title="Doc2Vec Summary" /><published>2019-01-10T00:00:00-06:00</published><updated>2019-01-10T00:00:00-06:00</updated><id>https://datapsyche.github.io/fastpages/markdown/2019/01/10/Doc2Vec-Paper</id><content type="html" xml:base="https://datapsyche.github.io/fastpages/markdown/2019/01/10/Doc2Vec-Paper.html">&lt;h1 id=&quot;distributed-representations-of-sentences-and-documents&quot;&gt;Distributed Representations of Sentences and Documents&lt;/h1&gt;

&lt;p&gt;Most algorithms typically require text input to be represented as a fixed-length vector. Bag of words / bag of n grams are the most common due to its simplicity, efficiency and often surprising accuracy. Bag of words has many disadvantages, Word order is gone and hence different sentences can have same representation. Bag of n grams considers word order in short context, as it has data sparsity and high dimensionality.&lt;/p&gt;

&lt;p&gt;Paragraph vectors is an unsupervised framework that learns continuous distributed vector representations for pieces of texts. The text can be of variable length ranging from sentences to documents.&lt;/p&gt;

&lt;p&gt;The vector representation is trained to be useful for predicting words in a paragraph. paragraph vector is concatenated with several word vectors from a paragraph and predicts following word in given context. Both word vector and paragraph vectors are trained by stochastic gradient descent with back propagation. paragraph vectors are unique among paragraph while word vectors are shared. At prediction time paragraph vectors are inferred by fixing word vectors and training the new paragraph vector until convergence.&lt;/p&gt;

&lt;p&gt;Paragraph vector is capable of constructing representations of input sequences of variable length. It is applicable for text of any length from sentences, paragraphs to documents.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Word vectors are the inspiration for paragraph vectors. Every word is mapped to a unique vector represented by a column in a matrix W.  The column is indexed by position of the word in vocabulary. The concatenation or sum of the vectors is then used as a feature for prediction of the next word in a sentence.  Given a sequence of training words w1,w2,w3,.. wt. Objective of the word vector model is to maximize the average log probability. Prediction is done via a multiclass classifier such as softmax. Neural Network based word vectors are usually trained using stochastic gradient descent and back propagation. Once the training is converged, words with similar meaning are mapped to a similar position in the vector space.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Paragraph Vectors&lt;/strong&gt; - are very much similar to word vectors. Word vectors are asked to contribute to the prediction task about the next word in the sentence. Hence even though word vectors are initialized randomly they eventually capture semantics as an indirect result of prediction task.  the paragraph vector and word vector are averaged or concatenated to predict the next word in a context. The only change when compared to word vector framework is  where h is constructed from W and D. This model is called Distributed Memory model of Paragraph Vectors (PV-DM) as the paragraph vector remembers what is missing from the current context of the paragraph.&lt;/p&gt;

&lt;p&gt;The contexts are fixed- length and sampled from a sliding window over the paragraph. The paragraph vector is shared across all the contexts but not with all paragraphs. But the word vector matrix is shared across all the paragraphs.&lt;/p&gt;</content><author><name></name></author><summary type="html">Distributed Representations of Sentences and Documents Most algorithms typically require text input to be represented as a fixed-length vector. Bag of words / bag of n grams are the most common due to its simplicity, efficiency and often surprising accuracy. Bag of words has many disadvantages, Word order is gone and hence different sentences can have same representation. Bag of n grams considers word order in short context, as it has data sparsity and high dimensionality. Paragraph vectors is an unsupervised framework that learns continuous distributed vector representations for pieces of texts. The text can be of variable length ranging from sentences to documents. The vector representation is trained to be useful for predicting words in a paragraph. paragraph vector is concatenated with several word vectors from a paragraph and predicts following word in given context. Both word vector and paragraph vectors are trained by stochastic gradient descent with back propagation. paragraph vectors are unique among paragraph while word vectors are shared. At prediction time paragraph vectors are inferred by fixing word vectors and training the new paragraph vector until convergence. Paragraph vector is capable of constructing representations of input sequences of variable length. It is applicable for text of any length from sentences, paragraphs to documents. Algorithm Word vectors are the inspiration for paragraph vectors. Every word is mapped to a unique vector represented by a column in a matrix W. The column is indexed by position of the word in vocabulary. The concatenation or sum of the vectors is then used as a feature for prediction of the next word in a sentence. Given a sequence of training words w1,w2,w3,.. wt. Objective of the word vector model is to maximize the average log probability. Prediction is done via a multiclass classifier such as softmax. Neural Network based word vectors are usually trained using stochastic gradient descent and back propagation. Once the training is converged, words with similar meaning are mapped to a similar position in the vector space. Paragraph Vectors - are very much similar to word vectors. Word vectors are asked to contribute to the prediction task about the next word in the sentence. Hence even though word vectors are initialized randomly they eventually capture semantics as an indirect result of prediction task. the paragraph vector and word vector are averaged or concatenated to predict the next word in a context. The only change when compared to word vector framework is where h is constructed from W and D. This model is called Distributed Memory model of Paragraph Vectors (PV-DM) as the paragraph vector remembers what is missing from the current context of the paragraph. The contexts are fixed- length and sampled from a sliding window over the paragraph. The paragraph vector is shared across all the contexts but not with all paragraphs. But the word vector matrix is shared across all the paragraphs.</summary></entry></feed>